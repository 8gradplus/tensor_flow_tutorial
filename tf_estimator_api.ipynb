{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The estimator API\n",
    "* [Tensorflow documentation](https://www.tensorflow.org/guide/estimators)\n",
    "* [Paper](https://arxiv.org/pdf/1708.02637.pdf)\n",
    "* `tensorflow.estimator`\n",
    "* **Don't use the depricated** `tf.contrib.learn.Estimator` class\n",
    "\n",
    "* High level API for machine learning tasks:\n",
    "    - Abstraction of Graphs and Sessions\n",
    "    - Training\n",
    "    - Prediction\n",
    "    - Evaluation\n",
    "    - Export for Serving\n",
    "    \n",
    "### Conceptual idea\n",
    "* Disentangle **data input pipeline** and **model**\n",
    "\n",
    "### [Data input pipeline:](https://www.tensorflow.org/guide/datasets)\n",
    "1. **Write data import function:**\n",
    "~~~~(.python)\n",
    "def train_input_fn(dataset):\n",
    "       ...\n",
    "       return feature_dict, labels\n",
    "~~~~\n",
    "2. **Define Feature columns:**\n",
    " * Each feature column has to be of type `tf.feature_column`\n",
    " * It identifies the feature name, its type, and any input pre-processing.\n",
    "~~~~(.python)\n",
    "feature_1 = tf.feature_column.numeric_column('feature_1')\n",
    "feature_2 = tf.feature_column.numeric_column('feature_2', \n",
    "                                              normalizer_fn=lambda x: x * 42)\n",
    "~~~~ \n",
    "\n",
    "### Model Fitting:\n",
    "1. **Instantiate model** with features columns from above\n",
    "~~~~(.python)\n",
    "classifier = tf.estimator.LinearClassifier(feature_columns: list)\n",
    "~~~~\n",
    "2. **Call train method** with data import function from above\n",
    "~~~~(.python)\n",
    "classifier.train(input_fn=train_input_fn, steps=2000)\n",
    "~~~~\n",
    "\n",
    "\n",
    "### Prediction\n",
    "1. **Define data importer for fit data** as for training above\n",
    "~~~~(.python)\n",
    "def predict_input_fn(dataset):\n",
    "       ...\n",
    "       return feature_dict, labels\n",
    "~~~~\n",
    "2. **Run predict method on trained model**\n",
    "~~~~(.python)\n",
    "predictions = classifier.predict(input_fn=predict_input_fn)\n",
    "~~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "supervised = namedtuple(\"supervised\", [\"features\", \"target\"])\n",
    "\n",
    "\n",
    "def split_test_train(data):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data.features, data.target, test_size = 0.2, random_state=5)\n",
    "    #return supervised(X_train, Y_train.reshape(-1, 1)), supervised(X_test, Y_test.reshape(-1, 1))\n",
    "    return supervised(X_train, Y_train), supervised(X_test, Y_test)\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "data = supervised(pd.DataFrame(housing.data, columns=housing.feature_names), \n",
    "                  pd.DataFrame(housing.target,columns=[\"price\"]))\n",
    "train, test = split_test_train(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input feature house age\n",
    "feature = train.features[[\"HouseAge\"]]\n",
    "# Configure a numeric feature column for house age.\n",
    "feature_columns = [tf.feature_column.numeric_column(\"HouseAge\")] # -> linear regressor\n",
    "# Define target variable\n",
    "targets = train.target[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpwdvcmomd\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpwdvcmomd', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f04385c5b70>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Use gradient descent as the optimizer for training the model.\n",
    "# Loss function incorporated in model\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.0000001)\n",
    "optimizer = tf.contrib.estimator.clip_gradients_by_norm(optimizer, 5.0)\n",
    "\n",
    "# Configure the linear regression model with our feature columns and optimizer.\n",
    "# Set a learning rate of 0.0000001 for Gradient Descent.\n",
    "linear_regressor = tf.estimator.LinearRegressor(\n",
    "    feature_columns=feature_columns,\n",
    "    optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "    \"\"\"Trains a linear regression model of one feature.\n",
    "  \n",
    "    Args:\n",
    "      features: pandas DataFrame of features\n",
    "      targets: pandas DataFrame of targets\n",
    "      batch_size: Size of batches to be passed to the model\n",
    "      shuffle: True or False. Whether to shuffle the data.\n",
    "      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n",
    "    Returns:\n",
    "      Tuple of (features, labels) for next data batch\n",
    "    \"\"\"\n",
    "  \n",
    "    # Convert pandas data into a dict of np arrays.\n",
    "    features = {key:np.array(value) for key,value in dict(features).items()}                                           \n",
    " \n",
    "    # Construct a dataset, and configure batching/repeating.\n",
    "    ds = tf.data.Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    # Shuffle the data, if specified.\n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(buffer_size=10000)\n",
    "    \n",
    "    # Return the next batch of data.\n",
    "    features, labels = ds.make_one_shot_iterator().get_next()\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpwdvcmomd/model.ckpt-1000\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into /tmp/tmpwdvcmomd/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.1064703, step = 1001\n",
      "INFO:tensorflow:global_step/sec: 1074.22\n",
      "INFO:tensorflow:loss = 7.228814, step = 1101 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 985.891\n",
      "INFO:tensorflow:loss = 2.8049595, step = 1201 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 917.275\n",
      "INFO:tensorflow:loss = 0.8651004, step = 1301 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 971.47\n",
      "INFO:tensorflow:loss = 1.0381328, step = 1401 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 887.554\n",
      "INFO:tensorflow:loss = 4.7686625, step = 1501 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 754.104\n",
      "INFO:tensorflow:loss = 3.3241026, step = 1601 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 1064.73\n",
      "INFO:tensorflow:loss = 4.298497, step = 1701 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1163.01\n",
      "INFO:tensorflow:loss = 11.065151, step = 1801 (0.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 1280.79\n",
      "INFO:tensorflow:loss = 3.0466673, step = 1901 (0.078 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/tmpwdvcmomd/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 14.485469.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x7f04385c59e8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regressor.train(input_fn = lambda:input_fn(feature, targets),\n",
    "                       steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's make a larger model with more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_features = train.features\n",
    "extended_features_columns = [tf.feature_column.numeric_column(\"HouseAge\"), \n",
    "                     tf.feature_column.numeric_column(\"MedInc\"),\n",
    "                     tf.feature_column.numeric_column(\"AveRooms\"),\n",
    "                     tf.feature_column.numeric_column(\"AveBedrms\"),\n",
    "                     tf.feature_column.numeric_column(\"Population\"),\n",
    "                     tf.feature_column.numeric_column(\"AveOccup\"),\n",
    "                     tf.feature_column.numeric_column(\"Latitude\"),\n",
    "                     tf.feature_column.numeric_column(\"Longitude\")                             \n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_9p2k0d8\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp_9p2k0d8', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0411dd94e0>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp_9p2k0d8/model.ckpt.\n",
      "INFO:tensorflow:loss = 4.0561957, step = 1\n",
      "INFO:tensorflow:global_step/sec: 746.608\n",
      "INFO:tensorflow:loss = 0.40761775, step = 101 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 999.405\n",
      "INFO:tensorflow:loss = 5.962312, step = 201 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 1021.46\n",
      "INFO:tensorflow:loss = 1.1725512, step = 301 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1017.12\n",
      "INFO:tensorflow:loss = 9.845411, step = 401 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 837.568\n",
      "INFO:tensorflow:loss = 1.7893763, step = 501 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 1017.61\n",
      "INFO:tensorflow:loss = 0.9974596, step = 601 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 914.346\n",
      "INFO:tensorflow:loss = 0.18874057, step = 701 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 992.528\n",
      "INFO:tensorflow:loss = 6.5948486, step = 801 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 822.193\n",
      "INFO:tensorflow:loss = 2.225636, step = 901 (0.119 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp_9p2k0d8/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 18.267004.\n"
     ]
    }
   ],
   "source": [
    "linear_regressor = tf.estimator.LinearRegressor(feature_columns=extended_features_columns, \n",
    "                                                optimizer=optimizer)\n",
    "\n",
    "linear_regressor.train(input_fn = lambda: input_fn(extended_features, targets),\n",
    "                       steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions regarding feature columns\n",
    "* If I comment out feature columns that occur in the training set tensor flow still runs. \n",
    "* $\\Rightarrow$ Are then only those features used for computation that are specified in the feature columns? \n",
    "# Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_data_input_fn(features):\n",
    "    features = {key:np.array(value) for key,value in dict(features).items()}                                           \n",
    "\n",
    "    # Construct a dataset, and configure batching/repeating.\n",
    "    ds = tf.data.Dataset.from_tensor_slices(features) # warning: 2GB limit\n",
    "    ds = ds.batch(1).repeat(1)  \n",
    "    \n",
    "    # Return the next batch of data.\n",
    "    features = ds.make_one_shot_iterator().get_next()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = linear_regressor.predict(input_fn=lambda: prediction_data_input_fn(test.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What type is the forecast?\n",
    "type(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Input graph does not contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp_9p2k0d8/model.ckpt-1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predictions': array([0.57823205], dtype=float32)}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's have a look at the element the itereator spits out\n",
    "next(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_result(forecast: iter):\n",
    "    targets = [t['predictions'][0] for t in forecast]\n",
    "    return np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = get_prediction_result(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning using generator expressions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predicion results: 4127\n",
      "Number of samples in the test set 4128\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of predicion results:\", predictions.shape[0])\n",
    "print(\"Number of samples in the test set\", test.target.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These number diverge!\n",
    "The reason is that we already took an example when we looked into the generator via the `next` method\n",
    "Generator expressions allow for one iteration only and then forget the already seen items\n",
    "So we should directly make a numpy array out of it in order not to loose any data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Input graph does not contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp_9p2k0d8/model.ckpt-1000\n"
     ]
    }
   ],
   "source": [
    "forecast = linear_regressor.predict(input_fn=lambda: prediction_data_input_fn(test.features))\n",
    "predictions = get_prediction_result(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "predictions.shape[0] == test.target.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "As there are several graph objects around at this point (tf estimators) we write the evaluation in its own graph\n",
    "\"\"\"\n",
    "new_graph = tf.Graph()\n",
    "\n",
    "with new_graph.as_default():\n",
    "    preds = tf.constant(predictions)\n",
    "    real = tf.constant(test.target)\n",
    "\n",
    "with tf.Session(graph=new_graph) as sess:\n",
    "    print(sess.graph is new_graph)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
