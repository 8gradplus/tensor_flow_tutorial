{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The estimator API\n",
    "* [Tensorflow documentation](https://www.tensorflow.org/guide/estimators)\n",
    "* [Paper](https://arxiv.org/pdf/1708.02637.pdf)\n",
    "* `tensorflow.estimator`\n",
    "* **Don't use the depricated** `tf.contrib.learn.Estimator` class\n",
    "\n",
    "* High level API for machine learning tasks:\n",
    "    - Abstraction of Graphs and Sessions\n",
    "    - Training\n",
    "    - Prediction\n",
    "    - Evaluation\n",
    "    - Export for Serving\n",
    "    \n",
    "### Conceptual idea\n",
    "* Disentangle **data input pipeline** and **model**\n",
    "\n",
    "### [Data input pipeline:](https://www.tensorflow.org/guide/datasets)\n",
    "1. **Write data import function:**\n",
    "~~~~(.python)\n",
    "def train_input_fn(dataset):\n",
    "       ...\n",
    "       return feature_dict, labels\n",
    "~~~~\n",
    "2. **Define Feature columns:**\n",
    " * Each feature column has to be of type `tf.feature_column`\n",
    " * It identifies the feature name, its type, and any input pre-processing.\n",
    "~~~~(.python)\n",
    "feature_1 = tf.feature_column.numeric_column('feature_1')\n",
    "feature_2 = tf.feature_column.numeric_column('feature_2', \n",
    "                                              normalizer_fn=lambda x: x * 42)\n",
    "~~~~ \n",
    "\n",
    "### Model Fitting:\n",
    "1. **Instantiate model** with features columns from above\n",
    "~~~~(.python)\n",
    "classifier = tf.estimator.LinearClassifier(feature_columns: list)\n",
    "~~~~\n",
    "2. **Call train method** with data import function from above\n",
    "~~~~(.python)\n",
    "classifier.train(input_fn=train_input_fn, steps=2000)\n",
    "~~~~\n",
    "\n",
    "\n",
    "### Prediction\n",
    "1. **Define data importer for fit data** as for training above\n",
    "~~~~(.python)\n",
    "def predict_input_fn(dataset):\n",
    "       ...\n",
    "       return feature_dict, labels\n",
    "~~~~\n",
    "2. **Run predict method on trained model**\n",
    "~~~~(.python)\n",
    "predictions = classifier.predict(input_fn=predict_input_fn)\n",
    "~~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "supervised = namedtuple(\"supervised\", [\"features\", \"target\"])\n",
    "\n",
    "\n",
    "def split_test_train(data):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data.features, data.target, test_size = 0.2, random_state=5)\n",
    "    #return supervised(X_train, Y_train.reshape(-1, 1)), supervised(X_test, Y_test.reshape(-1, 1))\n",
    "    return supervised(X_train, Y_train), supervised(X_test, Y_test)\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "data = supervised(pd.DataFrame(housing.data, columns=housing.feature_names), \n",
    "                  pd.DataFrame(housing.target,columns=[\"price\"]))\n",
    "train, test = split_test_train(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input feature house age\n",
    "feature = train.features[[\"HouseAge\"]]\n",
    "# Configure a numeric feature column for house age.\n",
    "feature_columns = [tf.feature_column.numeric_column(\"HouseAge\")] # -> linear regressor\n",
    "# Define target variable\n",
    "targets = train.target[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpwdvcmomd\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpwdvcmomd', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f04385c5b70>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Use gradient descent as the optimizer for training the model.\n",
    "# Loss function incorporated in model\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.0000001)\n",
    "optimizer = tf.contrib.estimator.clip_gradients_by_norm(optimizer, 5.0)\n",
    "\n",
    "# Configure the linear regression model with our feature columns and optimizer.\n",
    "# Set a learning rate of 0.0000001 for Gradient Descent.\n",
    "linear_regressor = tf.estimator.LinearRegressor(\n",
    "    feature_columns=feature_columns,\n",
    "    optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "    \"\"\"Trains a linear regression model of one feature.\n",
    "  \n",
    "    Args:\n",
    "      features: pandas DataFrame of features\n",
    "      targets: pandas DataFrame of targets\n",
    "      batch_size: Size of batches to be passed to the model\n",
    "      shuffle: True or False. Whether to shuffle the data.\n",
    "      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n",
    "    Returns:\n",
    "      Tuple of (features, labels) for next data batch\n",
    "    \"\"\"\n",
    "  \n",
    "    # Convert pandas data into a dict of np arrays.\n",
    "    features = {key:np.array(value) for key,value in dict(features).items()}                                           \n",
    " \n",
    "    # Construct a dataset, and configure batching/repeating.\n",
    "    ds = tf.data.Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    # Shuffle the data, if specified.\n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(buffer_size=10000)\n",
    "    \n",
    "    # Return the next batch of data.\n",
    "    features, labels = ds.make_one_shot_iterator().get_next()\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpwdvcmomd/model.ckpt-1000\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into /tmp/tmpwdvcmomd/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.1064703, step = 1001\n",
      "INFO:tensorflow:global_step/sec: 1074.22\n",
      "INFO:tensorflow:loss = 7.228814, step = 1101 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 985.891\n",
      "INFO:tensorflow:loss = 2.8049595, step = 1201 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 917.275\n",
      "INFO:tensorflow:loss = 0.8651004, step = 1301 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 971.47\n",
      "INFO:tensorflow:loss = 1.0381328, step = 1401 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 887.554\n",
      "INFO:tensorflow:loss = 4.7686625, step = 1501 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 754.104\n",
      "INFO:tensorflow:loss = 3.3241026, step = 1601 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 1064.73\n",
      "INFO:tensorflow:loss = 4.298497, step = 1701 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1163.01\n",
      "INFO:tensorflow:loss = 11.065151, step = 1801 (0.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 1280.79\n",
      "INFO:tensorflow:loss = 3.0466673, step = 1901 (0.078 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/tmpwdvcmomd/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 14.485469.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x7f04385c59e8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regressor.train(input_fn = lambda:input_fn(feature, targets),\n",
    "                       steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's make a larger model with more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_features = train.features\n",
    "extended_features_columns = [tf.feature_column.numeric_column(\"HouseAge\"), \n",
    "                     tf.feature_column.numeric_column(\"MedInc\"),\n",
    "                     tf.feature_column.numeric_column(\"AveRooms\"),\n",
    "                     tf.feature_column.numeric_column(\"AveBedrms\"),\n",
    "                     tf.feature_column.numeric_column(\"Population\"),\n",
    "                     tf.feature_column.numeric_column(\"AveOccup\"),\n",
    "                     tf.feature_column.numeric_column(\"Latitude\"),\n",
    "                     tf.feature_column.numeric_column(\"Longitude\")                             \n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_9p2k0d8\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp_9p2k0d8', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0411dd94e0>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp_9p2k0d8/model.ckpt.\n",
      "INFO:tensorflow:loss = 4.0561957, step = 1\n",
      "INFO:tensorflow:global_step/sec: 746.608\n",
      "INFO:tensorflow:loss = 0.40761775, step = 101 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 999.405\n",
      "INFO:tensorflow:loss = 5.962312, step = 201 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 1021.46\n",
      "INFO:tensorflow:loss = 1.1725512, step = 301 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1017.12\n",
      "INFO:tensorflow:loss = 9.845411, step = 401 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 837.568\n",
      "INFO:tensorflow:loss = 1.7893763, step = 501 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 1017.61\n",
      "INFO:tensorflow:loss = 0.9974596, step = 601 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 914.346\n",
      "INFO:tensorflow:loss = 0.18874057, step = 701 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 992.528\n",
      "INFO:tensorflow:loss = 6.5948486, step = 801 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 822.193\n",
      "INFO:tensorflow:loss = 2.225636, step = 901 (0.119 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp_9p2k0d8/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 18.267004.\n"
     ]
    }
   ],
   "source": [
    "linear_regressor = tf.estimator.LinearRegressor(feature_columns=extended_features_columns, \n",
    "                                                optimizer=optimizer)\n",
    "\n",
    "linear_regressor.train(input_fn = lambda: input_fn(extended_features, targets),\n",
    "                       steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions regarding feature columns\n",
    "* If I comment out feature columns that occur in the training set tensor flow still runs. \n",
    "* $\\Rightarrow$ Are then only those features used for computation that are specified in the feature columns? \n",
    "# Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_data_input_fn(features):\n",
    "    features = {key:np.array(value) for key,value in dict(features).items()}                                           \n",
    "\n",
    "    # Construct a dataset, and configure batching/repeating.\n",
    "    ds = tf.data.Dataset.from_tensor_slices(features) # warning: 2GB limit\n",
    "    ds = ds.batch(1).repeat(1)  \n",
    "    \n",
    "    # Return the next batch of data.\n",
    "    features = ds.make_one_shot_iterator().get_next()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = linear_regressor.predict(input_fn=lambda: prediction_data_input_fn(test.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What type is the forecast?\n",
    "type(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Input graph does not contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp_9p2k0d8/model.ckpt-1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predictions': array([0.57823205], dtype=float32)}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's have a look at the element the itereator spits out\n",
    "next(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_result(forecast: iter):\n",
    "    targets = [t['predictions'][0] for t in forecast]\n",
    "    return np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = get_prediction_result(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning using generator expressions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predicion results: 4127\n",
      "Number of samples in the test set 4128\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of predicion results:\", predictions.shape[0])\n",
    "print(\"Number of samples in the test set\", test.target.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These number diverge!\n",
    "The reason is that we already took an example when we looked into the generator via the `next` method\n",
    "Generator expressions allow for one iteration only and then forget the already seen items\n",
    "So we should directly make a numpy array out of it in order not to loose any data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Input graph does not contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp_9p2k0d8/model.ckpt-1000\n"
     ]
    }
   ],
   "source": [
    "forecast = linear_regressor.predict(input_fn=lambda: prediction_data_input_fn(test.features))\n",
    "predictions = get_prediction_result(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "predictions.shape[0] == test.target.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute errors\n",
    "* As an exercise we comput the errors using tensorflow\n",
    "* And compare the results with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does session use defined graph? True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Errors(mse=3.7333066, rmse=1.9321767)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "As there are several graph objects around at this point (tf estimators) we write the evaluation in its own graph\n",
    "\"\"\"\n",
    "Errors = namedtuple(\"Errors\", [\"mse\", \"rmse\"])\n",
    "\n",
    "new_graph = tf.Graph()\n",
    "with new_graph.as_default():\n",
    "    preds = tf.constant(predictions,  dtype=tf.float64, name=\"prediction_lables\")\n",
    "    real = tf.constant(test.target.values, dtype=tf.float64, name=\"real_labels\")\n",
    "    mse = tf.metrics.mean_squared_error(real, preds)[1]\n",
    "    rmse = tf.sqrt(mse)\n",
    "    errors = Errors(mse, rmse) \n",
    "    \n",
    "\n",
    "with tf.Session(graph=new_graph) as sess:\n",
    "    print(\"Does session use defined graph?\", sess.graph is new_graph)\n",
    "    #sess.run(tf.global_variables_initializer()) # Intitalize variables (not necessary for constants)\n",
    "    sess.run(tf.local_variables_initializer()) # Magically this needs to be done too\n",
    "    tf_errors = sess.run(errors)\n",
    "    \n",
    "tf_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Errors(mse=3.733306339134602, rmse=1.932176580733397)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "mean_squared_error = metrics.mean_squared_error(predictions, test.target.values)\n",
    "sk_errors = Errors(mean_squared_error, np.sqrt(mean_squared_error))\n",
    "sk_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step 1000\n",
      "linear/linear_model/AveBedrms/weights [[5.8685885e-07]]\n",
      "linear/linear_model/AveOccup/weights [[1.4909873e-06]]\n",
      "linear/linear_model/AveRooms/weights [[2.9085577e-06]]\n",
      "linear/linear_model/HouseAge/weights [[1.6422522e-05]]\n",
      "linear/linear_model/Latitude/weights [[1.9167783e-05]]\n",
      "linear/linear_model/Longitude/weights [[-6.4031934e-05]]\n",
      "linear/linear_model/MedInc/weights [[2.1488702e-06]]\n",
      "linear/linear_model/Population/weights [[0.00046557]]\n",
      "linear/linear_model/bias_weights [5.349638e-07]\n"
     ]
    }
   ],
   "source": [
    "names = linear_regressor.get_variable_names()\n",
    "for name in names:\n",
    "    print(name, linear_regressor.get_variable_value(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rid of this trange lambda expression via a callable:\n",
    "# Alternatively via currying\n",
    "class InputProvider:\n",
    "\n",
    "    def __init__(self, features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "        self.features = {key:np.array(value) for key,value in dict(features).items()} \n",
    "        self.targets = targets\n",
    "        self.batch_size=batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_epochs = num_epochs\n",
    " \n",
    "    def __call__(self):\n",
    "        ds = tf.data.Dataset.from_tensor_slices((self.features, self.targets)) # warning: 2GB limit\n",
    "        ds = ds.batch(self.batch_size).repeat(self.num_epochs)\n",
    "        if self.shuffle:\n",
    "            ds = ds.shuffle(buffer_size=10000)\n",
    "        features, labels = ds.make_one_shot_iterator().get_next()\n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmplnd6q4n3\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmplnd6q4n3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f03c0ba0c50>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmplnd6q4n3/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.32262403, step = 1\n",
      "INFO:tensorflow:global_step/sec: 888.509\n",
      "INFO:tensorflow:loss = 1.6980609, step = 101 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 1120.29\n",
      "INFO:tensorflow:loss = 24.407393, step = 201 (0.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 895.562\n",
      "INFO:tensorflow:loss = 1.7823681, step = 301 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 922.155\n",
      "INFO:tensorflow:loss = 0.07556853, step = 401 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 879.979\n",
      "INFO:tensorflow:loss = 0.4184379, step = 501 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.082\n",
      "INFO:tensorflow:loss = 0.4561502, step = 601 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 844.619\n",
      "INFO:tensorflow:loss = 0.8022476, step = 701 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 1131.76\n",
      "INFO:tensorflow:loss = 1.5471263, step = 801 (0.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 837.145\n",
      "INFO:tensorflow:loss = 1.7263381, step = 901 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 1103.06\n",
      "INFO:tensorflow:loss = 7.119636, step = 1001 (0.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 636.621\n",
      "INFO:tensorflow:loss = 17.821705, step = 1101 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 540.36\n",
      "INFO:tensorflow:loss = 0.5385967, step = 1201 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 837.924\n",
      "INFO:tensorflow:loss = 0.00020811443, step = 1301 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 1012.43\n",
      "INFO:tensorflow:loss = 0.38151777, step = 1401 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 1056.53\n",
      "INFO:tensorflow:loss = 2.6352966, step = 1501 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 1038.84\n",
      "INFO:tensorflow:loss = 0.0019740742, step = 1601 (0.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 861.496\n",
      "INFO:tensorflow:loss = 4.5786934, step = 1701 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 1099.78\n",
      "INFO:tensorflow:loss = 2.0113475, step = 1801 (0.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 843.727\n",
      "INFO:tensorflow:loss = 0.52114975, step = 1901 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 857.633\n",
      "INFO:tensorflow:loss = 0.95276093, step = 2001 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 803.536\n",
      "INFO:tensorflow:loss = 0.06099315, step = 2101 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 1103.2\n",
      "INFO:tensorflow:loss = 1.9335872, step = 2201 (0.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 848.148\n",
      "INFO:tensorflow:loss = 0.11449056, step = 2301 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 820.03\n",
      "INFO:tensorflow:loss = 0.26839682, step = 2401 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 855.157\n",
      "INFO:tensorflow:loss = 13.9842205, step = 2501 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 842.82\n",
      "INFO:tensorflow:loss = 18.269577, step = 2601 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 849.717\n",
      "INFO:tensorflow:loss = 0.16352566, step = 2701 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 801.411\n",
      "INFO:tensorflow:loss = 3.8084247, step = 2801 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 1019.61\n",
      "INFO:tensorflow:loss = 1.120391, step = 2901 (0.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 1078.15\n",
      "INFO:tensorflow:loss = 0.9514588, step = 3001 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 836.747\n",
      "INFO:tensorflow:loss = 0.24270265, step = 3101 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 852.047\n",
      "INFO:tensorflow:loss = 0.5333692, step = 3201 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.408\n",
      "INFO:tensorflow:loss = 0.078391805, step = 3301 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 1120.29\n",
      "INFO:tensorflow:loss = 0.26971403, step = 3401 (0.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.225\n",
      "INFO:tensorflow:loss = 7.1649303, step = 3501 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.817\n",
      "INFO:tensorflow:loss = 0.85488296, step = 3601 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 750.933\n",
      "INFO:tensorflow:loss = 0.22978805, step = 3701 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 789.157\n",
      "INFO:tensorflow:loss = 13.7485895, step = 3801 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 1067.15\n",
      "INFO:tensorflow:loss = 0.82334644, step = 3901 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 786.598\n",
      "INFO:tensorflow:loss = 1.3092484, step = 4001 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.599\n",
      "INFO:tensorflow:loss = 0.13939407, step = 4101 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 981.951\n",
      "INFO:tensorflow:loss = 1.7198976, step = 4201 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 799.564\n",
      "INFO:tensorflow:loss = 0.12104787, step = 4301 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 793.136\n",
      "INFO:tensorflow:loss = 1.3711883, step = 4401 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 1093.82\n",
      "INFO:tensorflow:loss = 0.016318854, step = 4501 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 794.964\n",
      "INFO:tensorflow:loss = 0.0016646088, step = 4601 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 757.181\n",
      "INFO:tensorflow:loss = 16.715626, step = 4701 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 798.278\n",
      "INFO:tensorflow:loss = 5.815591, step = 4801 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 879.931\n",
      "INFO:tensorflow:loss = 17.774874, step = 4901 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 791.309\n",
      "INFO:tensorflow:loss = 0.6025363, step = 5001 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.946\n",
      "INFO:tensorflow:loss = 0.07854077, step = 5101 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 989.65\n",
      "INFO:tensorflow:loss = 0.6046229, step = 5201 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 1245.24\n",
      "INFO:tensorflow:loss = 1.2258183, step = 5301 (0.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 965.577\n",
      "INFO:tensorflow:loss = 0.66193926, step = 5401 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 1278.22\n",
      "INFO:tensorflow:loss = 0.34273362, step = 5501 (0.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 982.915\n",
      "INFO:tensorflow:loss = 0.14611821, step = 5601 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 983.318\n",
      "INFO:tensorflow:loss = 0.16018343, step = 5701 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 724.957\n",
      "INFO:tensorflow:loss = 0.4257941, step = 5801 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.964\n",
      "INFO:tensorflow:loss = 0.6011744, step = 5901 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 805.909\n",
      "INFO:tensorflow:loss = 0.38887966, step = 6001 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 1190.38\n",
      "INFO:tensorflow:loss = 0.57562953, step = 6101 (0.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.142\n",
      "INFO:tensorflow:loss = 9.256639, step = 6201 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 735.947\n",
      "INFO:tensorflow:loss = 0.022938848, step = 6301 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 1225.88\n",
      "INFO:tensorflow:loss = 0.64974517, step = 6401 (0.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 934.812\n",
      "INFO:tensorflow:loss = 2.88308, step = 6501 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 1180.59\n",
      "INFO:tensorflow:loss = 13.952969, step = 6601 (0.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 955.834\n",
      "INFO:tensorflow:loss = 0.00022304048, step = 6701 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 961.161\n",
      "INFO:tensorflow:loss = 3.9226527, step = 6801 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 920.843\n",
      "INFO:tensorflow:loss = 5.4086668e-06, step = 6901 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 897.642\n",
      "INFO:tensorflow:loss = 0.25766993, step = 7001 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 1174.48\n",
      "INFO:tensorflow:loss = 12.250761, step = 7101 (0.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 957.466\n",
      "INFO:tensorflow:loss = 13.850774, step = 7201 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 933.892\n",
      "INFO:tensorflow:loss = 19.394638, step = 7301 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 944.906\n",
      "INFO:tensorflow:loss = 0.44409057, step = 7401 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 793.779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.20109978, step = 7501 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 610.902\n",
      "INFO:tensorflow:loss = 5.7284136, step = 7601 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 1234.17\n",
      "INFO:tensorflow:loss = 0.063685626, step = 7701 (0.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 1110.38\n",
      "INFO:tensorflow:loss = 0.98918515, step = 7801 (0.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 1231.36\n",
      "INFO:tensorflow:loss = 0.10935179, step = 7901 (0.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 1003.35\n",
      "INFO:tensorflow:loss = 5.2714276, step = 8001 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 750.5\n",
      "INFO:tensorflow:loss = 0.08102282, step = 8101 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 603.251\n",
      "INFO:tensorflow:loss = 7.0408173, step = 8201 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 1132.22\n",
      "INFO:tensorflow:loss = 0.93612725, step = 8301 (0.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.762\n",
      "INFO:tensorflow:loss = 5.0673966, step = 8401 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 964.146\n",
      "INFO:tensorflow:loss = 8.086709, step = 8501 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 1102.53\n",
      "INFO:tensorflow:loss = 0.012607657, step = 8601 (0.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 1083.21\n",
      "INFO:tensorflow:loss = 0.8148767, step = 8701 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 1064.51\n",
      "INFO:tensorflow:loss = 0.31709823, step = 8801 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1080.64\n",
      "INFO:tensorflow:loss = 2.5779698, step = 8901 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 1126.63\n",
      "INFO:tensorflow:loss = 17.897438, step = 9001 (0.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 1047.45\n",
      "INFO:tensorflow:loss = 1.4570844, step = 9101 (0.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 989.713\n",
      "INFO:tensorflow:loss = 0.022847904, step = 9201 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.235\n",
      "INFO:tensorflow:loss = 3.406425, step = 9301 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 948.712\n",
      "INFO:tensorflow:loss = 0.02499275, step = 9401 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 992.028\n",
      "INFO:tensorflow:loss = 1.2014976, step = 9501 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 750.128\n",
      "INFO:tensorflow:loss = 0.38876325, step = 9601 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 546.82\n",
      "INFO:tensorflow:loss = 11.7711315, step = 9701 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 762.462\n",
      "INFO:tensorflow:loss = 1.498527, step = 9801 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.366\n",
      "INFO:tensorflow:loss = 0.02198184, step = 9901 (0.146 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/tmplnd6q4n3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.022986718.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x7f03c17b1cf8>"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "linear_regressor = tf.estimator.LinearRegressor(feature_columns=extended_features_columns, \n",
    "                                    optimizer=optimizer)\n",
    "\n",
    "linear_regressor.train(input_fn = InputProvider(extended_features, targets),\n",
    "                       steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
