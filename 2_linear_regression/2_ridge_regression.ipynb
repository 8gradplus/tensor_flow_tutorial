{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression - some Theory\n",
    "\n",
    "* Simalar to ordinary linear regression the starting point is the least squares cost function $\\sum_{i=1}^N (y_i - \\hat y_i)^2$ together with the linear ansatz  $y_i =  x_i^T \\theta$.\n",
    "* This gives the objective function\n",
    "$$l = \\sum_{i=1}^N (x_i^T \\theta - \\hat y_i)^2  + \\alpha \\lVert \\theta \\rVert_2 ^2,$$\n",
    "where the additional regularization term $\\alpha \\lVert \\theta \\rVert_2 ^2$ with regularization strength $\\alpha$ occurs.\n",
    "* The optimum of this objective function can be found analytically\n",
    "$$\\theta ^* =  \\left( X^T X  + \\alpha \\mathbb 1 \\right)^{-1} X^T Y$$\n",
    "\n",
    "* Note that we could have also taken the expected version (per datapoint) - i.e divide by the number of datapoints $N$ and achieve the same optimium as $N$ just acts as a constant.\n",
    "\n",
    "\n",
    "### Todo: \n",
    "* Cholesky decomposition instead of inversion\n",
    "* Connection to PCA (Hasies or Murphy)\n",
    "\n",
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "Supervised = namedtuple(\"supervised\", [\"features\", \"target\", \"feature_names\"])\n",
    "\n",
    "def split_test_train(data):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data.features, data.target, test_size = 0.2, random_state=5)\n",
    "    train = Supervised(X_train, Y_train.reshape(-1, 1), feature_names=data.feature_names)\n",
    "    test = Supervised(X_test, Y_test.reshape(-1, 1), feature_names=data.feature_names)\n",
    "    return train, test \n",
    "\n",
    "\n",
    "def normalize(train: Supervised, test: Supervised):\n",
    "    mu = train.features.mean(axis=0)\n",
    "    std = train.features.std(axis=0)\n",
    "    train_scaled = Supervised(features=(train.features - mu) / std, \n",
    "                              target=train.target, \n",
    "                              feature_names=train.feature_names) \n",
    "    test_scaled = Supervised(features=(test.features - mu) / std, \n",
    "                             target=test.target, \n",
    "                             feature_names=test.feature_names)\n",
    "    return train_scaled, test_scaled\n",
    "\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "train_data, test_data = normalize(*split_test_train(Supervised(housing.data, housing.target, housing.feature_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression via the Normal equation - with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_intercept(features):\n",
    "    \"\"\"Add intercept to features\n",
    "    Todo: as an exercise use tensorflow\"\"\"\n",
    "    m, n = features.shape\n",
    "    return np.c_[np.ones((m, 1)), features]\n",
    "\n",
    "    \n",
    "def train(data, alpha):\n",
    "    X = add_intercept(data.features)\n",
    "    Y = data.target\n",
    "    XT = tf.transpose(X)\n",
    "    cov = tf.matmul(XT, X)\n",
    "    one = tf.eye(cov.shape[0], dtype=tf.dtypes.float64)\n",
    "    inv = tf.linalg.inv(cov + alpha * one)\n",
    "    return tf.matmul(tf.matmul(inv, XT), Y)\n",
    "\n",
    "\n",
    "def predict(data, theta):\n",
    "    return tf.matmul( add_intercept(data.features),  theta)\n",
    "\n",
    "theta_analytic = train(train_data, ALPHA)\n",
    "y_pred_analytic  = predict(test_data, theta_analytic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For comparison perform linear regression with scikit learn\n",
    "from sklearn.linear_model import Ridge\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_model = Ridge(alpha=ALPHA, fit_intercept=True, normalize=False)\n",
    "lin_model.fit(train_data.features, train_data.target)\n",
    "theta_sklearn = tf.concat((lin_model.intercept_, lin_model.coef_.flatten()), axis=0)\n",
    "y_pred_sklearn = lin_model.predict(test_data.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression as a Neural Network with Tensorflow / Keras \n",
    "* Idea: use keras wit 1 layer, identitiy as activation function\n",
    "* Assume that we could not find the minimizer analytically. \n",
    "* Thus we wish to find the minimzer computationally.\n",
    "* Regularization is taken into account via bias and kernel regularizers in a dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def plot_keras_training(history):\n",
    "    plt.figure(figsize=(15,4))\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "    plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)\n",
    "    plotter.plot({'Basic': history}, metric = \"mse\")\n",
    "    #plt.ylim([0, 3])\n",
    "    #plt.xlim([0,30])\n",
    "    plt.ylabel('MSE')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "ALPHA_TF = 0.5 * ALPHA / train_data.target.shape[0]\n",
    "    \n",
    "def build_model():\n",
    "    \"\"\"Regularization via kernel and bias regularizer\"\"\"\n",
    "    model = keras.Sequential([layers.Dense(1 \n",
    "                                           ,activation='linear'\n",
    "                                           ,input_shape=[8]\n",
    "                                           ,kernel_regularizer=regularizers.l2(ALPHA_TF) \n",
    "                                           ,bias_regularizer=regularizers.l2(ALPHA_TF))])\n",
    "    optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "    #optimizer = tf.keras.optimizers.SGD(0.001)\n",
    "    model.compile(loss=\"mse\",\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[\"mse\"])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, loss:0.5223,  mse:0.5221,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:0.5221,  mse:0.5219,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:0.5219,  mse:0.5217,  \n",
      "....................................................................................................\n",
      "Epoch: 300, loss:0.5219,  mse:0.5217,  \n",
      "....................................................................................................\n",
      "Epoch: 400, loss:0.5218,  mse:0.5216,  \n",
      "....................................................................................................\n",
      "Epoch: 500, loss:0.5217,  mse:0.5215,  \n",
      "....................................................................................................\n",
      "Epoch: 600, loss:0.5217,  mse:0.5215,  \n",
      "....................................................................................................\n",
      "Epoch: 700, loss:0.5217,  mse:0.5215,  \n",
      "....................................................................................................\n",
      "Epoch: 800, loss:0.5217,  mse:0.5215,  \n",
      "....................................................................................................\n",
      "Epoch: 900, loss:0.5217,  mse:0.5215,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, loss:0.5217,  mse:0.5215,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, loss:0.5217,  mse:0.5215,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, loss:0.5217,  mse:0.5215,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, loss:0.5217,  mse:0.5215,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, loss:0.5217,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 2000, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 2100, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 2200, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 2300, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 2400, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 2500, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 2600, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 2700, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 2800, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 2900, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 3000, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 3100, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 3200, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 3300, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 3400, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 3500, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 3600, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 3700, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 3800, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 3900, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 4000, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 4100, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 4200, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 4300, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 4400, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 4500, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 4600, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 4700, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 4800, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 4900, loss:0.5216,  mse:0.5214,  \n",
      "...................................................................................................."
     ]
    }
   ],
   "source": [
    "EPOCHS = 5000\n",
    "\n",
    "history = model.fit(\n",
    "  train_data.features, train_data.target,\n",
    "  epochs=EPOCHS, \n",
    "  batch_size = train_data.features.shape[0], validation_split = 0.0, verbose=0,\n",
    "  callbacks=[tfdocs.modeling.EpochDots()])\n",
    "\n",
    "theta_keras = tf.concat((model.weights[1], tf.reshape(model.weights[0], [8])), axis=0)\n",
    "y_pred_keras = model.predict(test_data.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Got Stuck?\n",
    "* The direct link for regularization is a bit tricky\n",
    "* In fact the reparametrization of $\\alpha$ seemed a bit odd. However, in the neural network above we optimized the MSE, \n",
    "$$l = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat y_i)^2$$\n",
    "and the regularizer act as $2 \\alpha \\lVert w \\rVert_2 ^2$ and  $2 \\alpha \\lVert b \\rVert_2 ^2$ on weights an biases respectively. \n",
    "Putting things together we effectively optimize the quantity \n",
    "$$l = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat y_i)^2 + 2 \\alpha ( \\lVert w \\rVert_2 ^2 +  \\lVert b \\rVert_2 ^2)$$\n",
    "And therefore $\\alpha \\rightarrow \\frac{\\alpha}{2N}$ gives an equivalent objective function as in the ridge regression formulation above.\n",
    "* It is illustrative to check if we start optimization at the known optimal weights (e.g. from sklearn) the optimizer should not move (up to some numerics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:0.5216,  mse:0.5214,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:0.5216,  mse:0.5214,  \n",
      "...................................................................................................."
     ]
    }
   ],
   "source": [
    "# Get intial kernel and bias weights from sklearn solution\n",
    "init_kernel = lambda shape, dtype: tf.constant(lin_model.coef_.reshape(shape), dtype=dtype)\n",
    "init_bias = lambda shape, dtype: tf.constant(lin_model.intercept_.reshape(shape), dtype=dtype)\n",
    "\n",
    "def build_model_at_optimum():\n",
    "    \"\"\"Ridge regression with weights initialized at optimum\"\"\"\n",
    "    model = keras.Sequential([layers.Dense(1 \n",
    "                                           ,activation='linear'\n",
    "                                           ,input_shape=[8]\n",
    "                                           ,kernel_regularizer=regularizers.l2(ALPHA_TF) \n",
    "                                           ,bias_regularizer=regularizers.l2(ALPHA_TF)\n",
    "                                           ,kernel_initializer=init_kernel\n",
    "                                           ,bias_initializer=init_bias\n",
    "                                          )])\n",
    "    optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "    model.compile(loss=\"mse\",\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[\"mse\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "EPOCHS = 300\n",
    "model_at_optimum = build_model_at_optimum()\n",
    "\n",
    "history = model_at_optimum.fit(\n",
    "  train_data.features, train_data.target,\n",
    "  epochs=EPOCHS, \n",
    "  batch_size = train_data.features.shape[0], validation_split = 0.0, verbose=0,\n",
    "  callbacks=[tfdocs.modeling.EpochDots()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression using the estimator API\n",
    "* Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparision of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return tf.reduce_sum((y_true - y_pred)**2) / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.5363392915031693>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(test_data.target,  y_pred_sklearn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.5363429005540788>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(test_data.target,  y_pred_analytic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.536342870415293>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(test_data.target,  y_pred_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float64, numpy=\n",
       "array([ 2.06389635,  0.82785305,  0.11548134, -0.28098196,  0.32407719,\n",
       "       -0.00341544, -0.04502633, -0.89539994, -0.86731315])>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float64, numpy=\n",
       "array([ 2.06377137,  0.82785305,  0.11548134, -0.28098196,  0.32407719,\n",
       "       -0.00341544, -0.04502633, -0.89539994, -0.86731315])>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(theta_analytic, (9,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
       "array([ 2.0638301 ,  0.8278724 ,  0.11544083, -0.28107285,  0.324193  ,\n",
       "       -0.00343003, -0.0450238 , -0.8957809 , -0.86769843], dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
