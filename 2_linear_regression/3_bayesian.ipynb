{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression - some Theory\n",
    "1. Include intercept in formulars.\n",
    "2. Speficy loss function\n",
    "2. Write down log Likelihood function\n",
    "3. Minimize + get Normal equation\n",
    "\n",
    "### Approach 1: Non-probabilisitc using loss function\n",
    "The easies approach to linear regression is to use the squared loss function, \n",
    "$$l = \\sum_{i=1}^N (y_i - \\hat y_i)^2,$$\n",
    "where $\\hat y_i$ is the predicted value and $y_i$ is the true value of sample $i$. Together with a linear, non probabilistic model for the. For feature vector $x_i$ (where the first component is per convention the constant one -aka known as intercept) the prediction is given by the linear model. In scalar product notation:\n",
    "$$y_i =  x_i^T \\theta,$$\n",
    "with coefficient vector $\\theta$. Rewriting this in Matrix notation to account for all sampels we get for the loss together with the linear model:\n",
    "$$l = (Y - X\\theta)^T (Y - X\\theta)$$\n",
    "Now we would like to find $\\theta^*$ that _minimizes_ the loss. \n",
    "Setting the derivative w.r.t. $\\theta$ of the loss function zero  gives the normal equation \n",
    "$$X^T(Y - X\\theta) = 0.$$\n",
    "If $X^T X$ is non-singular (this is the case when there are more traning examples than features because then $X^T X$ is positive definite) allows for finding the unique solutions of the normal equation, \n",
    "\n",
    "$$\\theta ^* =  \\left( X^T X  \\right)^{-1} X^T Y$$\n",
    "\n",
    "Note that this approach is non-probabilistic and thus, does not explicitly account for uncertainty  (as a probability distributions) in the data and coefficients.\n",
    "### Approach 2: Probabilistic  +  generative approach using max likelihood\n",
    "This approach introduces a probability distribution but does not explicitly consider a loss function. The  response is modelled  via a Normal distribution (\"Gauss error\") assuming constant standard deviation\n",
    "$$y_i = x_i^T \\theta + \\epsilon := \\mathcal N (x_i^T \\theta, \\sigma^2)$$\n",
    "In other words, the conditional distribtion  $p(y \\mid x, \\theta, \\sigma^2)$ is given by a Normal distribtion.\n",
    "The likelihood function is just the pdf of __all__ datapoints assuming i.i.d (this assumption in fact leads to the factorization), \n",
    "$$\\mathcal L = \\Pi_{i=1}^N p(y_i \\mid x, \\theta, \\sigma).$$\n",
    "As we are aiming to optimize $\\theta$ in a way, a striclty monotonic transformation is applied on the likelihood function. It leaves the optimum invariant. The standard procedure is thus to consider the the logarithm ot likelihood function:\n",
    "$$\\mathcal L_l = \\sum_{i=1}^N \\log p(y_i \\mid x, \\theta, \\sigma).$$\n",
    "Evaluating this expression for the Normal distribution gives\n",
    "$$\\mathcal L_l =  - \\frac{1}{2\\sigma^2}\\sum_{i=1}^N (y_i - x_i^T \\theta)^2  - \\frac{N}{2}log(2\\pi\\sigma^2) $$\n",
    "Now, we would like to _maximise_ the likelihood and thus the log likelihood with respect to $\\theta$. This is equivalent to _minimizing_ the negative of it. Throwing away terms that, don't depend on $\\theta$ gives the function for which we would like to find the minimizer. That is we want to solve this expression, \n",
    "$$\\text{argmin}_\\theta\\left( Y - X \\theta \\right )^T \\left( Y - X \\theta \\right ),$$\n",
    "where we have rewritten the sum of squares over all training data again in Matrix notation. But this is exactly the same problem as in approach one and this gives the same solution (under the same circumstances), \n",
    "\n",
    "$$\\theta ^* =  \\left( X^T X  \\right)^{-1} X^T Y$$\n",
    "\n",
    "**Remarks**\n",
    "* Note that this procedure only puts a probablilty distribution on the response $y$ while treating the remaining ingredients as variables (via the conditional pdf Ansatz). \n",
    "* This already implies that in this context the solutions $\\theta^*$ just tell how the pdf is parametrized (not even completely as we did not consider the optimum value of $\\sigma$).\n",
    "* In either case this approach does not really tell us how to predict a specific value $y$ for a given $x$. It just tells us the corresponding distribution of $y$. The fundamental reason is that we did not make any use of a loss function in this approach. \n",
    "* Pragmatically and in practice  of course, the prediction is made by plugging into the linear model as e.g. in the first appraoch\n",
    "* Note that a constant value for $\\sigma$ is called homoscedasticity. This implies that the variance does may not be a function of the features but only the mean within the Normal model for the response.\n",
    "* Furhtermore note that this approach does not consider uncertainties in the paramters. This would eventually require a Bayesian approach. \n",
    "\n",
    "\n",
    "### Bayesion models for linear regressions\n",
    "#### Model specification \n",
    "For a Bayesion approach we need the generative model from above \n",
    "$$y_i = x_i^T \\theta + \\epsilon := \\mathcal N (x_i^T \\theta, \\sigma^2)$$\n",
    "Together with a Prior for the model parameters: \n",
    "$$p(\\theta) := \\mathcal N (\\theta | \\mu_0, \\Sigma_0) $$\n",
    "\n",
    "* So the **prior** of $\\theta$ is itself parametrized by a mean $\\mu_0$ and $\\Sigma_\\0$. \n",
    "* As the normal distribution is conjugate to itself this choice will eventually yield analytic solutions.  \n",
    "* In this model we _assume_ that $\\sigma^2$ is known. We only want to learn the posterior for the model parameters $\\theta$\n",
    "\n",
    "\n",
    "#### Several classes of Bayesian models\n",
    "* In general the class of different models is obtained by\n",
    "* Different prior assumptions on the model paramaters. I.e., further constraining the prior $p(\\theta)$\n",
    "\n",
    "\n",
    "\n",
    "#### Inference \n",
    "* Corresponds to finding the posterior on the weights (given the data). \n",
    "* The basic ingredient for the joint (that in turn leads to the posterior) is the likelihood over all data as given above and the prior.\n",
    "\n",
    "$$p(\\theta | \\mathcal D, \\sigma^2, \\mu, \\Sigma) \\propto \\mathcal N (y | X^T\\theta, \\sigma^2) \\mathcal N (\\theta | \\mu, \\Sigma) = \\mathcal N (\\theta | \\mu_\\theta, \\Sigma_\\theta)  $$ \n",
    "* This gives again a Normal distribution with parameters \n",
    "$$\\Sigma_\\theta :=  \\left( \\Sigma_0^{-1}  + \\frac{1}{\\sigma^2}X^TX\\right)^{-1}$$\n",
    "$$\\mu_\\theta := \\Sigma_\\theta \\Sigma_0^{-1}\\mu_0 + \\frac{1}{\\sigma^2}\\Sigma_\\theta X^Ty$$\n",
    "\n",
    "\n",
    "\n",
    "#### Prediction\n",
    "* Corresponds to finding the pdf of a new $y^*$ given a new $x^*$ the historic data $\\mathcal D$, and (prior) model assumptions, $\\sigma^2$, $\\Sigma_0$, and $\\mu_0$. \n",
    "\n",
    "$$p(y^* | x^*, \\mathcal D, \\sigma, \\Sigma_0,  \\mu_0) = \\int d\\, \\theta ~ p(y^* | x^*, \\theta, \\sigma ) p(\\theta | \\mathcal D, \\Sigma_0, \\mu_0) \\\\ \n",
    "= \\int d \\theta \\, \\mathcal N(y^* | x^{*T}\\theta, \\sigma^2 ) \\,  p(\\theta | \\mathcal D, \\Sigma_0, \\mu_0) \\\\ \n",
    "= \\mathcal N (y^* | x^{*T}\\mu_\\theta, ~  \\sigma^2 + x^{*T} \\Sigma_\\theta x^{*}) $$ \n",
    "\n",
    "* So the expectation value of this prediction is given by the expectation value of the  $\\theta$-posterior, $\\mu$\n",
    "* The variance is determined by two contributions: \n",
    "    - by the apriori assumed variance of the observation noise $\\sigma^2$\n",
    "    - the variance in the parameters $\\Sigma$. \n",
    "* The latter contribution depends on how close a new datapoint is to the the training points.\n",
    "\n",
    "\n",
    "#### Remarks\n",
    "* So far it is assumed that $\\sigma$ is known. If we relax this requirement and try to learn $\\sigma$ as well than still a analytic solutions exist (see Murphy Chap 7.6.3 and 4.6.3). \n",
    "* But for the time beeing we assume that $\\sigma^2$ is known. \n",
    "* In the follwing we are treating special cases of the Bayesian approach presented so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apporach 4: Uncorrelated Bayesian Approach\n",
    "A Bayesian linar regression is a straightforward generalization, \n",
    "#### The model:\n",
    "Generative Process: $$y_i = x_i^T \\theta + \\epsilon \\propto \\mathcal N (y_i  | x_i^T \\theta, \\sigma^2)$$\n",
    "Prior on model Parameters: $$p(\\theta)  \\propto \\mathcal N (\\theta | 0, \\lambda ^{-1} \\mathbb 1 ) $$\n",
    "\n",
    "Making contact to the general case above we have: \n",
    "$$\n",
    "\\Sigma_0 =  \\lambda ^{-1} \\mathbb 1 \\\\ \n",
    "\\mu_0 = 0 $$\n",
    "\n",
    "\n",
    "#### Learning\n",
    "*  Follows from the general case above:  \n",
    "$$p(\\theta | X, \\sigma^2, \\lambda) = \\mathcal N \\left(\\theta ~ |~ \\mu_\\theta, \\Sigma_\\theta\\right)$$\n",
    "with \n",
    "$$\\mu_\\theta = \\left(X^TX + \\lambda \\sigma^2 \\mathbb 1\\right)^{-1}X^TY$$\n",
    "$$\\Sigma_\\theta =  \\left( \\lambda \\mathbb 1 + \\frac{1}{\\sigma^2} X^TX\\right)^{-1}$$\n",
    "* Note the feature correlation term the makes the posterior correlated!\n",
    "\n",
    "#### Inference \n",
    "Is given by the general case above\n",
    "$$p(y^* | x^*, \\sigma^2, \\lambda, \\mathcal D)= \\mathcal N (y^* | x^{*T}\\mu_\\theta, ~  \\sigma^2 + x^{*T} \\Sigma_\\theta x^{*})$$\n",
    "\n",
    "#### Ridge Regression as limiting case\n",
    "* Learning\n",
    "* $\\lambda \\sigma ^2 \\rightarrow \\lambda$ (regularization parameter)\n",
    "* $\\langle p(\\theta ~|~ \\mathcal D, \\lambda, \\sigma^2) \\rangle = \\left(XX^T + \\lambda \\mathbb 1 \\right)XY$ Estimator of ridge regression\n",
    "* Prediction\n",
    "* $\\langle p(y^* ~|~ x^* \\sigma^2 \\lambda, \\mathcal D)\\rangle = \\theta^T x^*$ (= Ridge Regression prediction)\n",
    "\n",
    "\n",
    "\n",
    "### Remarks\n",
    "References:\n",
    "- Murphy, Chap. 7\n",
    "- [Georg](https://github.com/yedivanseven/Bayesian/blob/master/LinearFit.ipynb)\n",
    "- https://brendanhasz.github.io/2018/12/03/tfp-regression\n",
    "- https://www.youtube.com/watch?v=Nr6jyodaFDo\n",
    "- https://stackoverflow.com/questions/59371283/bayesian-linear-regression-with-tensorflow-probability\n",
    "Approaches: \n",
    "- Via max likelihood https://www.quantstart.com/articles/Maximum-Likelihood-Estimation-for-Linear-Regression\n",
    "- Minimize quadratic error directly\n",
    "\n",
    "- Tensorflow regresson with probability layer:\n",
    "https://blog.tensorflow.org/2019/03/regression-with-probabilistic-layers-in.html\n",
    "\n",
    "- Tensorflow probablilty introduction: \n",
    "\n",
    "https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/TensorFlow_Probability_Case_Study_Covariance_Estimation.ipynb\n",
    "\n",
    "https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Generalized_Linear_Models.ipynb\n",
    "\n",
    "https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Understanding_TensorFlow_Distributions_Shapes.ipynb\n",
    "\n",
    "https://towardsdatascience.com/bayesian-neural-networks-in-10-mins-in-tfp-c735ec99384f\n",
    "\n",
    "https://www.youtube.com/watch?v=0TRHZdyp-xY\n",
    "\n",
    "# Observations\n",
    "* Heavily dependent on the modelparameters $\\lambda, \\sigma^2$\n",
    "* Which are determined by hand\n",
    "\n",
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: [[0.25238642]]\n",
      "Std: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow_core.data import Dataset as tfds\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "N = 10 #number of datapoints to generate\n",
    "D = 1   #number of dimensions\n",
    "STD = 1\n",
    "theta = tf.random.normal(shape=[D, 1], stddev=1)\n",
    "print(\"Theta:\", theta.numpy())\n",
    "x = tf.random.normal(shape=[N, D])\n",
    "y = tf.random.normal(shape=[N, 1], mean=tf.matmul(x, theta), stddev=STD)\n",
    "print(\"Std:\", STD)\n",
    "\n",
    "# Make a TensorFlow Dataset from training data\n",
    "data_train = tf.data.Dataset.from_tensor_slices((x, y)).shuffle(10000).batch(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UncorrelatedBayes:\n",
    "    \n",
    "    def __init__(self, s_square, l):\n",
    "        self.s_square = s_square\n",
    "        self.l = l \n",
    "        self.mu = None\n",
    "        self.sigma = None\n",
    "\n",
    "    def fit(self,  x, y):\n",
    "        inv_sigma  = self.l * tf.eye(x.shape[1])  +  tf.matmul(x, x, True) / self.s_square\n",
    "        self.sigma = tf.linalg.inv(inv_sigma)\n",
    "        self.mu = 1/self.s_square * tf.matmul(self.sigma,  tf.matmul(x, y, True))\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "        mu = tf.matmul(x, self.mu, True)\n",
    "        sigma = self.s_square + tf.matmul(x, tf.matmul(self.sigma, x), True)\n",
    "        return tfd.Normal(loc=mu, scale=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_list(xs):\n",
    "    return [x.numpy().flatten()[0] for x in xs ]\n",
    "\n",
    "def plot(ds: tfds, mu, std, grid, mus, lows, highs, model_params): \n",
    "    assert D == 1, \"this plot assumes one feature only\"\n",
    "    fig, ax = plt.subplots(nrows=2, figsize=(15,8))\n",
    "    iterator = iter(ds)\n",
    "    data = next(iterator) # todo iterate correctly\n",
    "    ax[0].plot(data[0], data[1], \"o\", color=\"red\", alpha=.5)\n",
    "    xs = tf.linspace(min(data[0])[0], max(data[0])[0], 100)\n",
    "    ax[0].plot(grid, mus, \"--\",  color='k',  lw=1, label=r\"$\\langle\\theta\\rangle$\")\n",
    "    ax[0].fill_between(grid, lows, highs, color='red', alpha=.3)\n",
    "    ax[0].grid()\n",
    "    ax[0].set_ylabel(\"y\", fontsize=12)\n",
    "    ax[0].set_xlabel(\"x\", fontsize=12)\n",
    "    msg = r\"Uncorrelated Bayesian Regression with given parameters: $\\sigma^2=${sigma_squared}, $\\lambda=${lambda}\"\n",
    "    ax[0].set_title(msg.format(**model_params), fontsize=15)\n",
    "\n",
    "    \n",
    "    ax[1].set_ylabel(r\"$p(\\theta)$\", fontsize=12)\n",
    "    ax[1].set_xlabel(r\"$\\theta$\", fontsize=12)\n",
    "    factor = 5\n",
    "    \n",
    "    # plot posterior on theta\n",
    "    xs = tf.linspace((mu - factor * std)[0, 0], (mu + factor * std)[0, 0], 300)\n",
    "    dist = tfd.Normal(loc=mu, scale=std)\n",
    "    ys = dist.prob(xs)\n",
    "    ax[1].plot(xs, tf.reshape(ys, [-1]), color=\"red\", alpha=.5)\n",
    "    #ax[1].grid()\n",
    "    ax[1].set_yticks([])\n",
    "    ax[0].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SIGMA_SQUARED = 1\n",
    "LAMBDA = 0.01\n",
    "fixed_model_params = {\"sigma_squared\": SIGMA_SQUARED, \"lambda\": LAMBDA}\n",
    "\n",
    "model = UncorrelatedBayes(SIGMA_SQUARED, LAMBDA)\n",
    "model.fit(x=x, y=y)\n",
    "\n",
    "xs = tf.reshape(tf.linspace(-5., 5., 100), [-1,1,1])\n",
    "ms = [model.predict(x) for x in xs]\n",
    "mus = to_list([m.mean() for m in ms])\n",
    "low = to_list([m.quantile(0.025) for m in ms])\n",
    "high = to_list([m.quantile(0.975) for m in ms])\n",
    "grid = to_list(xs)\n",
    "plot(data_train, model.mu, model.sigma, grid=grid, mus=mus, lows=low, highs=high, model_params=fixed_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network with Tensorflow / Keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 2         \n",
      "_________________________________________________________________\n",
      "distribution_lambda (Distrib ((None, 1), (None, 1))    0         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10 samples\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 0s 24ms/sample - loss: 2.4624\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 138us/sample - loss: 2.4591\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 299us/sample - loss: 2.4567\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 274us/sample - loss: 2.4547\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 275us/sample - loss: 2.4529\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 293us/sample - loss: 2.4513\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 283us/sample - loss: 2.4498\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 253us/sample - loss: 2.4484\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 200us/sample - loss: 2.4471\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 255us/sample - loss: 2.4457\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 265us/sample - loss: 2.4445\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 229us/sample - loss: 2.4433\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 344us/sample - loss: 2.4421\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 905us/sample - loss: 2.4409\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 470us/sample - loss: 2.4397\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 423us/sample - loss: 2.4386\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 685us/sample - loss: 2.4375\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 498us/sample - loss: 2.4364\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 304us/sample - loss: 2.4353\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 755us/sample - loss: 2.4342\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 288us/sample - loss: 2.4331\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 652us/sample - loss: 2.4321\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 311us/sample - loss: 2.4310\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 308us/sample - loss: 2.4299\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 311us/sample - loss: 2.4289\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 458us/sample - loss: 2.4279\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 311us/sample - loss: 2.4268\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 316us/sample - loss: 2.4258\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 241us/sample - loss: 2.4248\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 593us/sample - loss: 2.4238\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 311us/sample - loss: 2.4227\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 296us/sample - loss: 2.4217\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 387us/sample - loss: 2.4207\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 502us/sample - loss: 2.4197\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 652us/sample - loss: 2.4187\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 281us/sample - loss: 2.4177\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 198us/sample - loss: 2.4167\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 461us/sample - loss: 2.4157\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 199us/sample - loss: 2.4147\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 168us/sample - loss: 2.4137\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 393us/sample - loss: 2.4127\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 688us/sample - loss: 2.4117\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 430us/sample - loss: 2.4108\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 417us/sample - loss: 2.4098\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 265us/sample - loss: 2.4088\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 409us/sample - loss: 2.4078\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 210us/sample - loss: 2.4068\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 233us/sample - loss: 2.4058\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 220us/sample - loss: 2.4049\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 218us/sample - loss: 2.4039\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 730us/sample - loss: 2.4029\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 338us/sample - loss: 2.4019\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 299us/sample - loss: 2.4010\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 405us/sample - loss: 2.4000\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 222us/sample - loss: 2.3990\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 269us/sample - loss: 2.3981\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 215us/sample - loss: 2.3971\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 474us/sample - loss: 2.3961\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 226us/sample - loss: 2.3952\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 232us/sample - loss: 2.3942\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 226us/sample - loss: 2.3932\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 265us/sample - loss: 2.3923\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 204us/sample - loss: 2.3913\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 532us/sample - loss: 2.3903\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 573us/sample - loss: 2.3894\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 224us/sample - loss: 2.3884\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 282us/sample - loss: 2.3875\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 251us/sample - loss: 2.3865\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 259us/sample - loss: 2.3856\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 211us/sample - loss: 2.3846\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 249us/sample - loss: 2.3837\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 604us/sample - loss: 2.3827\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 248us/sample - loss: 2.3818\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 611us/sample - loss: 2.3808\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 266us/sample - loss: 2.3799\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 405us/sample - loss: 2.3789\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 317us/sample - loss: 2.3780\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 413us/sample - loss: 2.3770\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 444us/sample - loss: 2.3761\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 771us/sample - loss: 2.3751\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 0s 229us/sample - loss: 2.3742\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 164us/sample - loss: 2.3732\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 445us/sample - loss: 2.3723\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 561us/sample - loss: 2.3714\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 468us/sample - loss: 2.3704\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 384us/sample - loss: 2.3695\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 341us/sample - loss: 2.3685\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 437us/sample - loss: 2.3676\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 544us/sample - loss: 2.3667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 374us/sample - loss: 2.3657\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 354us/sample - loss: 2.3648\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 2.3639\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 441us/sample - loss: 2.3629\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 402us/sample - loss: 2.3620\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 438us/sample - loss: 2.3611\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 629us/sample - loss: 2.3602\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 641us/sample - loss: 2.3592\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 774us/sample - loss: 2.3583\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 233us/sample - loss: 2.3574\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 359us/sample - loss: 2.3565\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 274us/sample - loss: 2.3555\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 446us/sample - loss: 2.3546\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 820us/sample - loss: 2.3537\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 237us/sample - loss: 2.3528\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 287us/sample - loss: 2.3518\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 220us/sample - loss: 2.3509\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 530us/sample - loss: 2.3500\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 315us/sample - loss: 2.3491\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 553us/sample - loss: 2.3482\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 292us/sample - loss: 2.3473\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 269us/sample - loss: 2.3463\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 292us/sample - loss: 2.3454\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 468us/sample - loss: 2.3445\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 590us/sample - loss: 2.3436\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 0s 214us/sample - loss: 2.3427\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 203us/sample - loss: 2.3418\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 331us/sample - loss: 2.3409\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 760us/sample - loss: 2.3400\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 307us/sample - loss: 2.3391\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 419us/sample - loss: 2.3382\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 220us/sample - loss: 2.3373\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 0s 182us/sample - loss: 2.3363\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 0s 278us/sample - loss: 2.3354\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 0s 576us/sample - loss: 2.3345\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 0s 739us/sample - loss: 2.3336\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 0s 171us/sample - loss: 2.3327\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 0s 406us/sample - loss: 2.3318\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 0s 311us/sample - loss: 2.3309\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 0s 220us/sample - loss: 2.3300\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 0s 229us/sample - loss: 2.3291\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 0s 238us/sample - loss: 2.3282\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 0s 351us/sample - loss: 2.3273\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 0s 393us/sample - loss: 2.3265\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 0s 210us/sample - loss: 2.3256\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 0s 463us/sample - loss: 2.3247\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 0s 362us/sample - loss: 2.3238\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 0s 217us/sample - loss: 2.3229\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 0s 207us/sample - loss: 2.3220\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 0s 159us/sample - loss: 2.3211\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 0s 670us/sample - loss: 2.3202\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 0s 209us/sample - loss: 2.3193\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 0s 290us/sample - loss: 2.3184\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 0s 191us/sample - loss: 2.3175\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 0s 373us/sample - loss: 2.3167\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 0s 307us/sample - loss: 2.3158\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 0s 203us/sample - loss: 2.3149\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 0s 380us/sample - loss: 2.3140\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 0s 314us/sample - loss: 2.3131\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 0s 447us/sample - loss: 2.3122\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 0s 301us/sample - loss: 2.3114\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 0s 431us/sample - loss: 2.3105\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 0s 295us/sample - loss: 2.3096\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 0s 599us/sample - loss: 2.3087\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 0s 485us/sample - loss: 2.3078\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 0s 741us/sample - loss: 2.3070\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 0s 333us/sample - loss: 2.3061\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 0s 270us/sample - loss: 2.3052\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 0s 262us/sample - loss: 2.3043\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 0s 708us/sample - loss: 2.3035\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 0s 389us/sample - loss: 2.3026\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - 0s 267us/sample - loss: 2.3017\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - 0s 378us/sample - loss: 2.3008\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 2.3000\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - 0s 285us/sample - loss: 2.2991\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - 0s 318us/sample - loss: 2.2982\n",
      "Epoch 166/1000\n",
      "10/10 [==============================] - 0s 332us/sample - loss: 2.2974\n",
      "Epoch 167/1000\n",
      "10/10 [==============================] - 0s 636us/sample - loss: 2.2965\n",
      "Epoch 168/1000\n",
      "10/10 [==============================] - 0s 564us/sample - loss: 2.2956\n",
      "Epoch 169/1000\n",
      "10/10 [==============================] - 0s 318us/sample - loss: 2.2948\n",
      "Epoch 170/1000\n",
      "10/10 [==============================] - 0s 387us/sample - loss: 2.2939\n",
      "Epoch 171/1000\n",
      "10/10 [==============================] - 0s 681us/sample - loss: 2.2930\n",
      "Epoch 172/1000\n",
      "10/10 [==============================] - 0s 615us/sample - loss: 2.2922\n",
      "Epoch 173/1000\n",
      "10/10 [==============================] - 0s 349us/sample - loss: 2.2913\n",
      "Epoch 174/1000\n",
      "10/10 [==============================] - 0s 331us/sample - loss: 2.2904\n",
      "Epoch 175/1000\n",
      "10/10 [==============================] - 0s 341us/sample - loss: 2.2896\n",
      "Epoch 176/1000\n",
      "10/10 [==============================] - 0s 316us/sample - loss: 2.2887\n",
      "Epoch 177/1000\n",
      "10/10 [==============================] - 0s 661us/sample - loss: 2.2879\n",
      "Epoch 178/1000\n",
      "10/10 [==============================] - 0s 614us/sample - loss: 2.2870\n",
      "Epoch 179/1000\n",
      "10/10 [==============================] - 0s 301us/sample - loss: 2.2861\n",
      "Epoch 180/1000\n",
      "10/10 [==============================] - 0s 232us/sample - loss: 2.2853\n",
      "Epoch 181/1000\n",
      "10/10 [==============================] - 0s 383us/sample - loss: 2.2844\n",
      "Epoch 182/1000\n",
      "10/10 [==============================] - 0s 321us/sample - loss: 2.2836\n",
      "Epoch 183/1000\n",
      "10/10 [==============================] - 0s 368us/sample - loss: 2.2827\n",
      "Epoch 184/1000\n",
      "10/10 [==============================] - 0s 232us/sample - loss: 2.2819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185/1000\n",
      "10/10 [==============================] - 0s 222us/sample - loss: 2.2810\n",
      "Epoch 186/1000\n",
      "10/10 [==============================] - 0s 701us/sample - loss: 2.2802\n",
      "Epoch 187/1000\n",
      "10/10 [==============================] - 0s 346us/sample - loss: 2.2793\n",
      "Epoch 188/1000\n",
      "10/10 [==============================] - 0s 238us/sample - loss: 2.2785\n",
      "Epoch 189/1000\n",
      "10/10 [==============================] - 0s 444us/sample - loss: 2.2776\n",
      "Epoch 190/1000\n",
      "10/10 [==============================] - 0s 313us/sample - loss: 2.2768\n",
      "Epoch 191/1000\n",
      "10/10 [==============================] - 0s 298us/sample - loss: 2.2759\n",
      "Epoch 192/1000\n",
      "10/10 [==============================] - 0s 318us/sample - loss: 2.2751\n",
      "Epoch 193/1000\n",
      "10/10 [==============================] - 0s 286us/sample - loss: 2.2742\n",
      "Epoch 194/1000\n",
      "10/10 [==============================] - 0s 321us/sample - loss: 2.2734\n",
      "Epoch 195/1000\n",
      "10/10 [==============================] - 0s 312us/sample - loss: 2.2725\n",
      "Epoch 196/1000\n",
      "10/10 [==============================] - 0s 298us/sample - loss: 2.2717\n",
      "Epoch 197/1000\n",
      "10/10 [==============================] - 0s 348us/sample - loss: 2.2708\n",
      "Epoch 198/1000\n",
      "10/10 [==============================] - 0s 367us/sample - loss: 2.2700\n",
      "Epoch 199/1000\n",
      "10/10 [==============================] - 0s 755us/sample - loss: 2.2691\n",
      "Epoch 200/1000\n",
      "10/10 [==============================] - 0s 725us/sample - loss: 2.2683\n",
      "Epoch 201/1000\n",
      "10/10 [==============================] - 0s 458us/sample - loss: 2.2675\n",
      "Epoch 202/1000\n",
      "10/10 [==============================] - 0s 303us/sample - loss: 2.2666\n",
      "Epoch 203/1000\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 2.2658\n",
      "Epoch 204/1000\n",
      "10/10 [==============================] - 0s 327us/sample - loss: 2.2649\n",
      "Epoch 205/1000\n",
      "10/10 [==============================] - 0s 767us/sample - loss: 2.2641\n",
      "Epoch 206/1000\n",
      "10/10 [==============================] - 0s 526us/sample - loss: 2.2633\n",
      "Epoch 207/1000\n",
      "10/10 [==============================] - 0s 689us/sample - loss: 2.2624\n",
      "Epoch 208/1000\n",
      "10/10 [==============================] - 0s 279us/sample - loss: 2.2616\n",
      "Epoch 209/1000\n",
      "10/10 [==============================] - 0s 472us/sample - loss: 2.2608\n",
      "Epoch 210/1000\n",
      "10/10 [==============================] - 0s 271us/sample - loss: 2.2599\n",
      "Epoch 211/1000\n",
      "10/10 [==============================] - 0s 320us/sample - loss: 2.2591\n",
      "Epoch 212/1000\n",
      "10/10 [==============================] - 0s 363us/sample - loss: 2.2583\n",
      "Epoch 213/1000\n",
      "10/10 [==============================] - 0s 643us/sample - loss: 2.2574\n",
      "Epoch 214/1000\n",
      "10/10 [==============================] - 0s 702us/sample - loss: 2.2566\n",
      "Epoch 215/1000\n",
      "10/10 [==============================] - 0s 361us/sample - loss: 2.2558\n",
      "Epoch 216/1000\n",
      "10/10 [==============================] - 0s 392us/sample - loss: 2.2549\n",
      "Epoch 217/1000\n",
      "10/10 [==============================] - 0s 374us/sample - loss: 2.2541\n",
      "Epoch 218/1000\n",
      "10/10 [==============================] - 0s 649us/sample - loss: 2.2533\n",
      "Epoch 219/1000\n",
      "10/10 [==============================] - 0s 367us/sample - loss: 2.2524\n",
      "Epoch 220/1000\n",
      "10/10 [==============================] - 0s 381us/sample - loss: 2.2516\n",
      "Epoch 221/1000\n",
      "10/10 [==============================] - 0s 444us/sample - loss: 2.2508\n",
      "Epoch 222/1000\n",
      "10/10 [==============================] - 0s 231us/sample - loss: 2.2500\n",
      "Epoch 223/1000\n",
      "10/10 [==============================] - 0s 388us/sample - loss: 2.2491\n",
      "Epoch 224/1000\n",
      "10/10 [==============================] - 0s 203us/sample - loss: 2.2483\n",
      "Epoch 225/1000\n",
      "10/10 [==============================] - 0s 200us/sample - loss: 2.2475\n",
      "Epoch 226/1000\n",
      "10/10 [==============================] - 0s 202us/sample - loss: 2.2467\n",
      "Epoch 227/1000\n",
      "10/10 [==============================] - 0s 649us/sample - loss: 2.2459\n",
      "Epoch 228/1000\n",
      "10/10 [==============================] - 0s 254us/sample - loss: 2.2450\n",
      "Epoch 229/1000\n",
      "10/10 [==============================] - 0s 316us/sample - loss: 2.2442\n",
      "Epoch 230/1000\n",
      "10/10 [==============================] - 0s 951us/sample - loss: 2.2434\n",
      "Epoch 231/1000\n",
      "10/10 [==============================] - 0s 217us/sample - loss: 2.2426\n",
      "Epoch 232/1000\n",
      "10/10 [==============================] - 0s 234us/sample - loss: 2.2418\n",
      "Epoch 233/1000\n",
      "10/10 [==============================] - 0s 416us/sample - loss: 2.2409\n",
      "Epoch 234/1000\n",
      "10/10 [==============================] - 0s 306us/sample - loss: 2.2401\n",
      "Epoch 235/1000\n",
      "10/10 [==============================] - 0s 175us/sample - loss: 2.2393\n",
      "Epoch 236/1000\n",
      "10/10 [==============================] - 0s 192us/sample - loss: 2.2385\n",
      "Epoch 237/1000\n",
      "10/10 [==============================] - 0s 271us/sample - loss: 2.2377\n",
      "Epoch 238/1000\n",
      "10/10 [==============================] - 0s 169us/sample - loss: 2.2369\n",
      "Epoch 239/1000\n",
      "10/10 [==============================] - 0s 264us/sample - loss: 2.2361\n",
      "Epoch 240/1000\n",
      "10/10 [==============================] - 0s 295us/sample - loss: 2.2352\n",
      "Epoch 241/1000\n",
      "10/10 [==============================] - 0s 280us/sample - loss: 2.2344\n",
      "Epoch 242/1000\n",
      "10/10 [==============================] - 0s 482us/sample - loss: 2.2336\n",
      "Epoch 243/1000\n",
      "10/10 [==============================] - 0s 340us/sample - loss: 2.2328\n",
      "Epoch 244/1000\n",
      "10/10 [==============================] - 0s 291us/sample - loss: 2.2320\n",
      "Epoch 245/1000\n",
      "10/10 [==============================] - 0s 400us/sample - loss: 2.2312\n",
      "Epoch 246/1000\n",
      "10/10 [==============================] - 0s 305us/sample - loss: 2.2304\n",
      "Epoch 247/1000\n",
      "10/10 [==============================] - 0s 815us/sample - loss: 2.2296\n",
      "Epoch 248/1000\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 2.2288\n",
      "Epoch 249/1000\n",
      "10/10 [==============================] - 0s 324us/sample - loss: 2.2280\n",
      "Epoch 250/1000\n",
      "10/10 [==============================] - 0s 272us/sample - loss: 2.2272\n",
      "Epoch 251/1000\n",
      "10/10 [==============================] - 0s 387us/sample - loss: 2.2264\n",
      "Epoch 252/1000\n",
      "10/10 [==============================] - 0s 597us/sample - loss: 2.2256\n",
      "Epoch 253/1000\n",
      "10/10 [==============================] - 0s 374us/sample - loss: 2.2248\n",
      "Epoch 254/1000\n",
      "10/10 [==============================] - 0s 406us/sample - loss: 2.2240\n",
      "Epoch 255/1000\n",
      "10/10 [==============================] - 0s 234us/sample - loss: 2.2232\n",
      "Epoch 256/1000\n",
      "10/10 [==============================] - 0s 290us/sample - loss: 2.2224\n",
      "Epoch 257/1000\n",
      "10/10 [==============================] - 0s 484us/sample - loss: 2.2216\n",
      "Epoch 258/1000\n",
      "10/10 [==============================] - 0s 368us/sample - loss: 2.2208\n",
      "Epoch 259/1000\n",
      "10/10 [==============================] - 0s 389us/sample - loss: 2.2200\n",
      "Epoch 260/1000\n",
      "10/10 [==============================] - 0s 336us/sample - loss: 2.2192\n",
      "Epoch 261/1000\n",
      "10/10 [==============================] - 0s 414us/sample - loss: 2.2184\n",
      "Epoch 262/1000\n",
      "10/10 [==============================] - 0s 572us/sample - loss: 2.2176\n",
      "Epoch 263/1000\n",
      "10/10 [==============================] - 0s 236us/sample - loss: 2.2168\n",
      "Epoch 264/1000\n",
      "10/10 [==============================] - 0s 238us/sample - loss: 2.2160\n",
      "Epoch 265/1000\n",
      "10/10 [==============================] - 0s 728us/sample - loss: 2.2152\n",
      "Epoch 266/1000\n",
      "10/10 [==============================] - 0s 321us/sample - loss: 2.2144\n",
      "Epoch 267/1000\n",
      "10/10 [==============================] - 0s 559us/sample - loss: 2.2136\n",
      "Epoch 268/1000\n",
      "10/10 [==============================] - 0s 352us/sample - loss: 2.2128\n",
      "Epoch 269/1000\n",
      "10/10 [==============================] - 0s 482us/sample - loss: 2.2121\n",
      "Epoch 270/1000\n",
      "10/10 [==============================] - 0s 465us/sample - loss: 2.2113\n",
      "Epoch 271/1000\n",
      "10/10 [==============================] - 0s 211us/sample - loss: 2.2105\n",
      "Epoch 272/1000\n",
      "10/10 [==============================] - 0s 212us/sample - loss: 2.2097\n",
      "Epoch 273/1000\n",
      "10/10 [==============================] - 0s 186us/sample - loss: 2.2089\n",
      "Epoch 274/1000\n",
      "10/10 [==============================] - 0s 367us/sample - loss: 2.2081\n",
      "Epoch 275/1000\n",
      "10/10 [==============================] - 0s 454us/sample - loss: 2.2073\n",
      "Epoch 276/1000\n",
      "10/10 [==============================] - 0s 372us/sample - loss: 2.2065\n",
      "Epoch 277/1000\n",
      "10/10 [==============================] - 0s 285us/sample - loss: 2.2058\n",
      "Epoch 278/1000\n",
      "10/10 [==============================] - 0s 599us/sample - loss: 2.2050\n",
      "Epoch 279/1000\n",
      "10/10 [==============================] - 0s 229us/sample - loss: 2.2042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/1000\n",
      "10/10 [==============================] - 0s 304us/sample - loss: 2.2034\n",
      "Epoch 281/1000\n",
      "10/10 [==============================] - 0s 549us/sample - loss: 2.2026\n",
      "Epoch 282/1000\n",
      "10/10 [==============================] - 0s 270us/sample - loss: 2.2019\n",
      "Epoch 283/1000\n",
      "10/10 [==============================] - 0s 331us/sample - loss: 2.2011\n",
      "Epoch 284/1000\n",
      "10/10 [==============================] - 0s 263us/sample - loss: 2.2003\n",
      "Epoch 285/1000\n",
      "10/10 [==============================] - 0s 312us/sample - loss: 2.1995\n",
      "Epoch 286/1000\n",
      "10/10 [==============================] - 0s 478us/sample - loss: 2.1988\n",
      "Epoch 287/1000\n",
      "10/10 [==============================] - 0s 893us/sample - loss: 2.1980\n",
      "Epoch 288/1000\n",
      "10/10 [==============================] - 0s 330us/sample - loss: 2.1972\n",
      "Epoch 289/1000\n",
      "10/10 [==============================] - 0s 228us/sample - loss: 2.1964\n",
      "Epoch 290/1000\n",
      "10/10 [==============================] - 0s 366us/sample - loss: 2.1957\n",
      "Epoch 291/1000\n",
      "10/10 [==============================] - 0s 517us/sample - loss: 2.1949\n",
      "Epoch 292/1000\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 2.1941\n",
      "Epoch 293/1000\n",
      "10/10 [==============================] - 0s 336us/sample - loss: 2.1933\n",
      "Epoch 294/1000\n",
      "10/10 [==============================] - 0s 230us/sample - loss: 2.1926\n",
      "Epoch 295/1000\n",
      "10/10 [==============================] - 0s 578us/sample - loss: 2.1918\n",
      "Epoch 296/1000\n",
      "10/10 [==============================] - 0s 349us/sample - loss: 2.1910\n",
      "Epoch 297/1000\n",
      "10/10 [==============================] - 0s 588us/sample - loss: 2.1903\n",
      "Epoch 298/1000\n",
      "10/10 [==============================] - 0s 377us/sample - loss: 2.1895\n",
      "Epoch 299/1000\n",
      "10/10 [==============================] - 0s 493us/sample - loss: 2.1887\n",
      "Epoch 300/1000\n",
      "10/10 [==============================] - 0s 705us/sample - loss: 2.1880\n",
      "Epoch 301/1000\n",
      "10/10 [==============================] - 0s 278us/sample - loss: 2.1872\n",
      "Epoch 302/1000\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 2.1864\n",
      "Epoch 303/1000\n",
      "10/10 [==============================] - 0s 774us/sample - loss: 2.1857\n",
      "Epoch 304/1000\n",
      "10/10 [==============================] - 0s 310us/sample - loss: 2.1849\n",
      "Epoch 305/1000\n",
      "10/10 [==============================] - 0s 284us/sample - loss: 2.1842\n",
      "Epoch 306/1000\n",
      "10/10 [==============================] - 0s 678us/sample - loss: 2.1834\n",
      "Epoch 307/1000\n",
      "10/10 [==============================] - 0s 407us/sample - loss: 2.1826\n",
      "Epoch 308/1000\n",
      "10/10 [==============================] - 0s 509us/sample - loss: 2.1819\n",
      "Epoch 309/1000\n",
      "10/10 [==============================] - 0s 266us/sample - loss: 2.1811\n",
      "Epoch 310/1000\n",
      "10/10 [==============================] - 0s 345us/sample - loss: 2.1804\n",
      "Epoch 311/1000\n",
      "10/10 [==============================] - 0s 276us/sample - loss: 2.1796\n",
      "Epoch 312/1000\n",
      "10/10 [==============================] - 0s 393us/sample - loss: 2.1789\n",
      "Epoch 313/1000\n",
      "10/10 [==============================] - 0s 297us/sample - loss: 2.1781\n",
      "Epoch 314/1000\n",
      "10/10 [==============================] - 0s 504us/sample - loss: 2.1773\n",
      "Epoch 315/1000\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 2.1766\n",
      "Epoch 316/1000\n",
      "10/10 [==============================] - 0s 511us/sample - loss: 2.1758\n",
      "Epoch 317/1000\n",
      "10/10 [==============================] - 0s 207us/sample - loss: 2.1751\n",
      "Epoch 318/1000\n",
      "10/10 [==============================] - 0s 289us/sample - loss: 2.1743\n",
      "Epoch 319/1000\n",
      "10/10 [==============================] - 0s 249us/sample - loss: 2.1736\n",
      "Epoch 320/1000\n",
      "10/10 [==============================] - 0s 239us/sample - loss: 2.1728\n",
      "Epoch 321/1000\n",
      "10/10 [==============================] - 0s 603us/sample - loss: 2.1721\n",
      "Epoch 322/1000\n",
      "10/10 [==============================] - 0s 326us/sample - loss: 2.1713\n",
      "Epoch 323/1000\n",
      "10/10 [==============================] - 0s 358us/sample - loss: 2.1706\n",
      "Epoch 324/1000\n",
      "10/10 [==============================] - 0s 209us/sample - loss: 2.1698\n",
      "Epoch 325/1000\n",
      "10/10 [==============================] - 0s 239us/sample - loss: 2.1691\n",
      "Epoch 326/1000\n",
      "10/10 [==============================] - 0s 275us/sample - loss: 2.1683\n",
      "Epoch 327/1000\n",
      "10/10 [==============================] - 0s 509us/sample - loss: 2.1676\n",
      "Epoch 328/1000\n",
      "10/10 [==============================] - 0s 456us/sample - loss: 2.1669\n",
      "Epoch 329/1000\n",
      "10/10 [==============================] - 0s 246us/sample - loss: 2.1661\n",
      "Epoch 330/1000\n",
      "10/10 [==============================] - 0s 375us/sample - loss: 2.1654\n",
      "Epoch 331/1000\n",
      "10/10 [==============================] - 0s 469us/sample - loss: 2.1646\n",
      "Epoch 332/1000\n",
      "10/10 [==============================] - 0s 422us/sample - loss: 2.1639\n",
      "Epoch 333/1000\n",
      "10/10 [==============================] - 0s 277us/sample - loss: 2.1632\n",
      "Epoch 334/1000\n",
      "10/10 [==============================] - 0s 227us/sample - loss: 2.1624\n",
      "Epoch 335/1000\n",
      "10/10 [==============================] - 0s 221us/sample - loss: 2.1617\n",
      "Epoch 336/1000\n",
      "10/10 [==============================] - 0s 306us/sample - loss: 2.1609\n",
      "Epoch 337/1000\n",
      "10/10 [==============================] - 0s 477us/sample - loss: 2.1602\n",
      "Epoch 338/1000\n",
      "10/10 [==============================] - 0s 794us/sample - loss: 2.1595\n",
      "Epoch 339/1000\n",
      "10/10 [==============================] - 0s 201us/sample - loss: 2.1587\n",
      "Epoch 340/1000\n",
      "10/10 [==============================] - 0s 515us/sample - loss: 2.1580\n",
      "Epoch 341/1000\n",
      "10/10 [==============================] - 0s 309us/sample - loss: 2.1573\n",
      "Epoch 342/1000\n",
      "10/10 [==============================] - 0s 231us/sample - loss: 2.1565\n",
      "Epoch 343/1000\n",
      "10/10 [==============================] - 0s 549us/sample - loss: 2.1558\n",
      "Epoch 344/1000\n",
      "10/10 [==============================] - 0s 227us/sample - loss: 2.1551\n",
      "Epoch 345/1000\n",
      "10/10 [==============================] - 0s 299us/sample - loss: 2.1543\n",
      "Epoch 346/1000\n",
      "10/10 [==============================] - 0s 228us/sample - loss: 2.1536\n",
      "Epoch 347/1000\n",
      "10/10 [==============================] - 0s 208us/sample - loss: 2.1529\n",
      "Epoch 348/1000\n",
      "10/10 [==============================] - 0s 196us/sample - loss: 2.1522\n",
      "Epoch 349/1000\n",
      "10/10 [==============================] - 0s 237us/sample - loss: 2.1514\n",
      "Epoch 350/1000\n",
      "10/10 [==============================] - 0s 998us/sample - loss: 2.1507\n",
      "Epoch 351/1000\n",
      "10/10 [==============================] - 0s 400us/sample - loss: 2.1500\n",
      "Epoch 352/1000\n",
      "10/10 [==============================] - 0s 242us/sample - loss: 2.1492\n",
      "Epoch 353/1000\n",
      "10/10 [==============================] - 0s 227us/sample - loss: 2.1485\n",
      "Epoch 354/1000\n",
      "10/10 [==============================] - 0s 401us/sample - loss: 2.1478\n",
      "Epoch 355/1000\n",
      "10/10 [==============================] - 0s 916us/sample - loss: 2.1471\n",
      "Epoch 356/1000\n",
      "10/10 [==============================] - 0s 279us/sample - loss: 2.1464\n",
      "Epoch 357/1000\n",
      "10/10 [==============================] - 0s 522us/sample - loss: 2.1456\n",
      "Epoch 358/1000\n",
      "10/10 [==============================] - 0s 520us/sample - loss: 2.1449\n",
      "Epoch 359/1000\n",
      "10/10 [==============================] - 0s 403us/sample - loss: 2.1442\n",
      "Epoch 360/1000\n",
      "10/10 [==============================] - 0s 277us/sample - loss: 2.1435\n",
      "Epoch 361/1000\n",
      "10/10 [==============================] - 0s 524us/sample - loss: 2.1428\n",
      "Epoch 362/1000\n",
      "10/10 [==============================] - 0s 430us/sample - loss: 2.1420\n",
      "Epoch 363/1000\n",
      "10/10 [==============================] - 0s 410us/sample - loss: 2.1413\n",
      "Epoch 364/1000\n",
      "10/10 [==============================] - 0s 974us/sample - loss: 2.1406\n",
      "Epoch 365/1000\n",
      "10/10 [==============================] - 0s 408us/sample - loss: 2.1399\n",
      "Epoch 366/1000\n",
      "10/10 [==============================] - 0s 241us/sample - loss: 2.1392\n",
      "Epoch 367/1000\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 2.1385\n",
      "Epoch 368/1000\n",
      "10/10 [==============================] - 0s 694us/sample - loss: 2.1377\n",
      "Epoch 369/1000\n",
      "10/10 [==============================] - 0s 423us/sample - loss: 2.1370\n",
      "Epoch 370/1000\n",
      "10/10 [==============================] - 0s 727us/sample - loss: 2.1363\n",
      "Epoch 371/1000\n",
      "10/10 [==============================] - 0s 231us/sample - loss: 2.1356\n",
      "Epoch 372/1000\n",
      "10/10 [==============================] - 0s 189us/sample - loss: 2.1349\n",
      "Epoch 373/1000\n",
      "10/10 [==============================] - 0s 239us/sample - loss: 2.1342\n",
      "Epoch 374/1000\n",
      "10/10 [==============================] - 0s 663us/sample - loss: 2.1335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 375/1000\n",
      "10/10 [==============================] - 0s 197us/sample - loss: 2.1328\n",
      "Epoch 376/1000\n",
      "10/10 [==============================] - 0s 457us/sample - loss: 2.1321\n",
      "Epoch 377/1000\n",
      "10/10 [==============================] - 0s 381us/sample - loss: 2.1314\n",
      "Epoch 378/1000\n",
      "10/10 [==============================] - 0s 303us/sample - loss: 2.1307\n",
      "Epoch 379/1000\n",
      "10/10 [==============================] - 0s 309us/sample - loss: 2.1300\n",
      "Epoch 380/1000\n",
      "10/10 [==============================] - 0s 692us/sample - loss: 2.1293\n",
      "Epoch 381/1000\n",
      "10/10 [==============================] - 0s 275us/sample - loss: 2.1286\n",
      "Epoch 382/1000\n",
      "10/10 [==============================] - 0s 399us/sample - loss: 2.1279\n",
      "Epoch 383/1000\n",
      "10/10 [==============================] - 0s 286us/sample - loss: 2.1271\n",
      "Epoch 384/1000\n",
      "10/10 [==============================] - 0s 293us/sample - loss: 2.1264\n",
      "Epoch 385/1000\n",
      "10/10 [==============================] - 0s 518us/sample - loss: 2.1257\n",
      "Epoch 386/1000\n",
      "10/10 [==============================] - 0s 506us/sample - loss: 2.1251\n",
      "Epoch 387/1000\n",
      "10/10 [==============================] - 0s 610us/sample - loss: 2.1244\n",
      "Epoch 388/1000\n",
      "10/10 [==============================] - 0s 574us/sample - loss: 2.1237\n",
      "Epoch 389/1000\n",
      "10/10 [==============================] - 0s 396us/sample - loss: 2.1230\n",
      "Epoch 390/1000\n",
      "10/10 [==============================] - 0s 224us/sample - loss: 2.1223\n",
      "Epoch 391/1000\n",
      "10/10 [==============================] - 0s 212us/sample - loss: 2.1216\n",
      "Epoch 392/1000\n",
      "10/10 [==============================] - 0s 428us/sample - loss: 2.1209\n",
      "Epoch 393/1000\n",
      "10/10 [==============================] - 0s 404us/sample - loss: 2.1202\n",
      "Epoch 394/1000\n",
      "10/10 [==============================] - 0s 412us/sample - loss: 2.1195\n",
      "Epoch 395/1000\n",
      "10/10 [==============================] - 0s 286us/sample - loss: 2.1188\n",
      "Epoch 396/1000\n",
      "10/10 [==============================] - 0s 340us/sample - loss: 2.1181\n",
      "Epoch 397/1000\n",
      "10/10 [==============================] - 0s 518us/sample - loss: 2.1174\n",
      "Epoch 398/1000\n",
      "10/10 [==============================] - 0s 190us/sample - loss: 2.1167\n",
      "Epoch 399/1000\n",
      "10/10 [==============================] - 0s 216us/sample - loss: 2.1160\n",
      "Epoch 400/1000\n",
      "10/10 [==============================] - 0s 255us/sample - loss: 2.1153\n",
      "Epoch 401/1000\n",
      "10/10 [==============================] - 0s 445us/sample - loss: 2.1147\n",
      "Epoch 402/1000\n",
      "10/10 [==============================] - 0s 265us/sample - loss: 2.1140\n",
      "Epoch 403/1000\n",
      "10/10 [==============================] - 0s 441us/sample - loss: 2.1133\n",
      "Epoch 404/1000\n",
      "10/10 [==============================] - 0s 903us/sample - loss: 2.1126\n",
      "Epoch 405/1000\n",
      "10/10 [==============================] - 0s 710us/sample - loss: 2.1119\n",
      "Epoch 406/1000\n",
      "10/10 [==============================] - 0s 718us/sample - loss: 2.1112\n",
      "Epoch 407/1000\n",
      "10/10 [==============================] - 0s 326us/sample - loss: 2.1105\n",
      "Epoch 408/1000\n",
      "10/10 [==============================] - 0s 829us/sample - loss: 2.1099\n",
      "Epoch 409/1000\n",
      "10/10 [==============================] - 0s 420us/sample - loss: 2.1092\n",
      "Epoch 410/1000\n",
      "10/10 [==============================] - 0s 517us/sample - loss: 2.1085\n",
      "Epoch 411/1000\n",
      "10/10 [==============================] - 0s 259us/sample - loss: 2.1078\n",
      "Epoch 412/1000\n",
      "10/10 [==============================] - 0s 799us/sample - loss: 2.1071\n",
      "Epoch 413/1000\n",
      "10/10 [==============================] - 0s 405us/sample - loss: 2.1065\n",
      "Epoch 414/1000\n",
      "10/10 [==============================] - 0s 524us/sample - loss: 2.1058\n",
      "Epoch 415/1000\n",
      "10/10 [==============================] - 0s 524us/sample - loss: 2.1051\n",
      "Epoch 416/1000\n",
      "10/10 [==============================] - 0s 458us/sample - loss: 2.1044\n",
      "Epoch 417/1000\n",
      "10/10 [==============================] - 0s 468us/sample - loss: 2.1038\n",
      "Epoch 418/1000\n",
      "10/10 [==============================] - 0s 351us/sample - loss: 2.1031\n",
      "Epoch 419/1000\n",
      "10/10 [==============================] - 0s 406us/sample - loss: 2.1024\n",
      "Epoch 420/1000\n",
      "10/10 [==============================] - 0s 321us/sample - loss: 2.1017\n",
      "Epoch 421/1000\n",
      "10/10 [==============================] - 0s 304us/sample - loss: 2.1011\n",
      "Epoch 422/1000\n",
      "10/10 [==============================] - 0s 391us/sample - loss: 2.1004\n",
      "Epoch 423/1000\n",
      "10/10 [==============================] - 0s 206us/sample - loss: 2.0997\n",
      "Epoch 424/1000\n",
      "10/10 [==============================] - 0s 367us/sample - loss: 2.0991\n",
      "Epoch 425/1000\n",
      "10/10 [==============================] - 0s 471us/sample - loss: 2.0984\n",
      "Epoch 426/1000\n",
      "10/10 [==============================] - 0s 638us/sample - loss: 2.0977\n",
      "Epoch 427/1000\n",
      "10/10 [==============================] - 0s 485us/sample - loss: 2.0971\n",
      "Epoch 428/1000\n",
      "10/10 [==============================] - 0s 268us/sample - loss: 2.0964\n",
      "Epoch 429/1000\n",
      "10/10 [==============================] - 0s 311us/sample - loss: 2.0957\n",
      "Epoch 430/1000\n",
      "10/10 [==============================] - 0s 247us/sample - loss: 2.0951\n",
      "Epoch 431/1000\n",
      "10/10 [==============================] - 0s 354us/sample - loss: 2.0944\n",
      "Epoch 432/1000\n",
      "10/10 [==============================] - 0s 431us/sample - loss: 2.0937\n",
      "Epoch 433/1000\n",
      "10/10 [==============================] - 0s 572us/sample - loss: 2.0931\n",
      "Epoch 434/1000\n",
      "10/10 [==============================] - 0s 374us/sample - loss: 2.0924\n",
      "Epoch 435/1000\n",
      "10/10 [==============================] - 0s 209us/sample - loss: 2.0917\n",
      "Epoch 436/1000\n",
      "10/10 [==============================] - 0s 257us/sample - loss: 2.0911\n",
      "Epoch 437/1000\n",
      "10/10 [==============================] - 0s 560us/sample - loss: 2.0904\n",
      "Epoch 438/1000\n",
      "10/10 [==============================] - 0s 355us/sample - loss: 2.0898\n",
      "Epoch 439/1000\n",
      "10/10 [==============================] - 0s 335us/sample - loss: 2.0891\n",
      "Epoch 440/1000\n",
      "10/10 [==============================] - 0s 230us/sample - loss: 2.0884\n",
      "Epoch 441/1000\n",
      "10/10 [==============================] - 0s 468us/sample - loss: 2.0878\n",
      "Epoch 442/1000\n",
      "10/10 [==============================] - 0s 361us/sample - loss: 2.0871\n",
      "Epoch 443/1000\n",
      "10/10 [==============================] - 0s 418us/sample - loss: 2.0865\n",
      "Epoch 444/1000\n",
      "10/10 [==============================] - 0s 255us/sample - loss: 2.0858\n",
      "Epoch 445/1000\n",
      "10/10 [==============================] - 0s 238us/sample - loss: 2.0852\n",
      "Epoch 446/1000\n",
      "10/10 [==============================] - 0s 594us/sample - loss: 2.0845\n",
      "Epoch 447/1000\n",
      "10/10 [==============================] - 0s 535us/sample - loss: 2.0839\n",
      "Epoch 448/1000\n",
      "10/10 [==============================] - 0s 312us/sample - loss: 2.0832\n",
      "Epoch 449/1000\n",
      "10/10 [==============================] - 0s 359us/sample - loss: 2.0826\n",
      "Epoch 450/1000\n",
      "10/10 [==============================] - 0s 292us/sample - loss: 2.0819\n",
      "Epoch 451/1000\n",
      "10/10 [==============================] - 0s 276us/sample - loss: 2.0813\n",
      "Epoch 452/1000\n",
      "10/10 [==============================] - 0s 900us/sample - loss: 2.0806\n",
      "Epoch 453/1000\n",
      "10/10 [==============================] - 0s 264us/sample - loss: 2.0800\n",
      "Epoch 454/1000\n",
      "10/10 [==============================] - 0s 461us/sample - loss: 2.0793\n",
      "Epoch 455/1000\n",
      "10/10 [==============================] - 0s 326us/sample - loss: 2.0787\n",
      "Epoch 456/1000\n",
      "10/10 [==============================] - 0s 378us/sample - loss: 2.0780\n",
      "Epoch 457/1000\n",
      "10/10 [==============================] - 0s 513us/sample - loss: 2.0774\n",
      "Epoch 458/1000\n",
      "10/10 [==============================] - 0s 269us/sample - loss: 2.0767\n",
      "Epoch 459/1000\n",
      "10/10 [==============================] - 0s 344us/sample - loss: 2.0761\n",
      "Epoch 460/1000\n",
      "10/10 [==============================] - 0s 300us/sample - loss: 2.0755\n",
      "Epoch 461/1000\n",
      "10/10 [==============================] - 0s 290us/sample - loss: 2.0748\n",
      "Epoch 462/1000\n",
      "10/10 [==============================] - 0s 447us/sample - loss: 2.0742\n",
      "Epoch 463/1000\n",
      "10/10 [==============================] - 0s 647us/sample - loss: 2.0735\n",
      "Epoch 464/1000\n",
      "10/10 [==============================] - 0s 302us/sample - loss: 2.0729\n",
      "Epoch 465/1000\n",
      "10/10 [==============================] - 0s 332us/sample - loss: 2.0723\n",
      "Epoch 466/1000\n",
      "10/10 [==============================] - 0s 298us/sample - loss: 2.0716\n",
      "Epoch 467/1000\n",
      "10/10 [==============================] - 0s 242us/sample - loss: 2.0710\n",
      "Epoch 468/1000\n",
      "10/10 [==============================] - 0s 449us/sample - loss: 2.0704\n",
      "Epoch 469/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 442us/sample - loss: 2.0697\n",
      "Epoch 470/1000\n",
      "10/10 [==============================] - 0s 318us/sample - loss: 2.0691\n",
      "Epoch 471/1000\n",
      "10/10 [==============================] - 0s 306us/sample - loss: 2.0684\n",
      "Epoch 472/1000\n",
      "10/10 [==============================] - 0s 340us/sample - loss: 2.0678\n",
      "Epoch 473/1000\n",
      "10/10 [==============================] - 0s 515us/sample - loss: 2.0672\n",
      "Epoch 474/1000\n",
      "10/10 [==============================] - 0s 453us/sample - loss: 2.0666\n",
      "Epoch 475/1000\n",
      "10/10 [==============================] - 0s 504us/sample - loss: 2.0659\n",
      "Epoch 476/1000\n",
      "10/10 [==============================] - 0s 404us/sample - loss: 2.0653\n",
      "Epoch 477/1000\n",
      "10/10 [==============================] - 0s 499us/sample - loss: 2.0647\n",
      "Epoch 478/1000\n",
      "10/10 [==============================] - 0s 445us/sample - loss: 2.0640\n",
      "Epoch 479/1000\n",
      "10/10 [==============================] - 0s 343us/sample - loss: 2.0634\n",
      "Epoch 480/1000\n",
      "10/10 [==============================] - 0s 802us/sample - loss: 2.0628\n",
      "Epoch 481/1000\n",
      "10/10 [==============================] - 0s 445us/sample - loss: 2.0622\n",
      "Epoch 482/1000\n",
      "10/10 [==============================] - 0s 344us/sample - loss: 2.0615\n",
      "Epoch 483/1000\n",
      "10/10 [==============================] - 0s 241us/sample - loss: 2.0609\n",
      "Epoch 484/1000\n",
      "10/10 [==============================] - 0s 518us/sample - loss: 2.0603\n",
      "Epoch 485/1000\n",
      "10/10 [==============================] - 0s 340us/sample - loss: 2.0597\n",
      "Epoch 486/1000\n",
      "10/10 [==============================] - 0s 251us/sample - loss: 2.0590\n",
      "Epoch 487/1000\n",
      "10/10 [==============================] - 0s 177us/sample - loss: 2.0584\n",
      "Epoch 488/1000\n",
      "10/10 [==============================] - 0s 212us/sample - loss: 2.0578\n",
      "Epoch 489/1000\n",
      "10/10 [==============================] - 0s 297us/sample - loss: 2.0572\n",
      "Epoch 490/1000\n",
      "10/10 [==============================] - 0s 508us/sample - loss: 2.0566\n",
      "Epoch 491/1000\n",
      "10/10 [==============================] - 0s 334us/sample - loss: 2.0559\n",
      "Epoch 492/1000\n",
      "10/10 [==============================] - 0s 248us/sample - loss: 2.0553\n",
      "Epoch 493/1000\n",
      "10/10 [==============================] - 0s 245us/sample - loss: 2.0547\n",
      "Epoch 494/1000\n",
      "10/10 [==============================] - 0s 242us/sample - loss: 2.0541\n",
      "Epoch 495/1000\n",
      "10/10 [==============================] - 0s 405us/sample - loss: 2.0535\n",
      "Epoch 496/1000\n",
      "10/10 [==============================] - 0s 219us/sample - loss: 2.0529\n",
      "Epoch 497/1000\n",
      "10/10 [==============================] - 0s 198us/sample - loss: 2.0522\n",
      "Epoch 498/1000\n",
      "10/10 [==============================] - 0s 172us/sample - loss: 2.0516\n",
      "Epoch 499/1000\n",
      "10/10 [==============================] - 0s 182us/sample - loss: 2.0510\n",
      "Epoch 500/1000\n",
      "10/10 [==============================] - 0s 560us/sample - loss: 2.0504\n",
      "Epoch 501/1000\n",
      "10/10 [==============================] - 0s 487us/sample - loss: 2.0498\n",
      "Epoch 502/1000\n",
      "10/10 [==============================] - 0s 350us/sample - loss: 2.0492\n",
      "Epoch 503/1000\n",
      "10/10 [==============================] - 0s 291us/sample - loss: 2.0486\n",
      "Epoch 504/1000\n",
      "10/10 [==============================] - 0s 510us/sample - loss: 2.0480\n",
      "Epoch 505/1000\n",
      "10/10 [==============================] - 0s 383us/sample - loss: 2.0474\n",
      "Epoch 506/1000\n",
      "10/10 [==============================] - 0s 257us/sample - loss: 2.0468\n",
      "Epoch 507/1000\n",
      "10/10 [==============================] - 0s 261us/sample - loss: 2.0461\n",
      "Epoch 508/1000\n",
      "10/10 [==============================] - 0s 337us/sample - loss: 2.0455\n",
      "Epoch 509/1000\n",
      "10/10 [==============================] - 0s 275us/sample - loss: 2.0449\n",
      "Epoch 510/1000\n",
      "10/10 [==============================] - 0s 257us/sample - loss: 2.0443\n",
      "Epoch 511/1000\n",
      "10/10 [==============================] - 0s 361us/sample - loss: 2.0437\n",
      "Epoch 512/1000\n",
      "10/10 [==============================] - 0s 270us/sample - loss: 2.0431\n",
      "Epoch 513/1000\n",
      "10/10 [==============================] - 0s 802us/sample - loss: 2.0425\n",
      "Epoch 514/1000\n",
      "10/10 [==============================] - 0s 315us/sample - loss: 2.0419\n",
      "Epoch 515/1000\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 2.0413\n",
      "Epoch 516/1000\n",
      "10/10 [==============================] - 0s 301us/sample - loss: 2.0407\n",
      "Epoch 517/1000\n",
      "10/10 [==============================] - 0s 868us/sample - loss: 2.0401\n",
      "Epoch 518/1000\n",
      "10/10 [==============================] - 0s 781us/sample - loss: 2.0395\n",
      "Epoch 519/1000\n",
      "10/10 [==============================] - 0s 233us/sample - loss: 2.0389\n",
      "Epoch 520/1000\n",
      "10/10 [==============================] - 0s 227us/sample - loss: 2.0383\n",
      "Epoch 521/1000\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 2.0377\n",
      "Epoch 522/1000\n",
      "10/10 [==============================] - 0s 738us/sample - loss: 2.0372\n",
      "Epoch 523/1000\n",
      "10/10 [==============================] - 0s 411us/sample - loss: 2.0366\n",
      "Epoch 524/1000\n",
      "10/10 [==============================] - 0s 298us/sample - loss: 2.0360\n",
      "Epoch 525/1000\n",
      "10/10 [==============================] - 0s 261us/sample - loss: 2.0354\n",
      "Epoch 526/1000\n",
      "10/10 [==============================] - 0s 512us/sample - loss: 2.0348\n",
      "Epoch 527/1000\n",
      "10/10 [==============================] - 0s 441us/sample - loss: 2.0342\n",
      "Epoch 528/1000\n",
      "10/10 [==============================] - 0s 289us/sample - loss: 2.0336\n",
      "Epoch 529/1000\n",
      "10/10 [==============================] - 0s 245us/sample - loss: 2.0330\n",
      "Epoch 530/1000\n",
      "10/10 [==============================] - 0s 265us/sample - loss: 2.0324\n",
      "Epoch 531/1000\n",
      "10/10 [==============================] - 0s 285us/sample - loss: 2.0318\n",
      "Epoch 532/1000\n",
      "10/10 [==============================] - 0s 883us/sample - loss: 2.0312\n",
      "Epoch 533/1000\n",
      "10/10 [==============================] - 0s 249us/sample - loss: 2.0307\n",
      "Epoch 534/1000\n",
      "10/10 [==============================] - 0s 390us/sample - loss: 2.0301\n",
      "Epoch 535/1000\n",
      "10/10 [==============================] - 0s 263us/sample - loss: 2.0295\n",
      "Epoch 536/1000\n",
      "10/10 [==============================] - 0s 864us/sample - loss: 2.0289\n",
      "Epoch 537/1000\n",
      "10/10 [==============================] - 0s 324us/sample - loss: 2.0283\n",
      "Epoch 538/1000\n",
      "10/10 [==============================] - 0s 269us/sample - loss: 2.0277\n",
      "Epoch 539/1000\n",
      "10/10 [==============================] - 0s 328us/sample - loss: 2.0272\n",
      "Epoch 540/1000\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 2.0266\n",
      "Epoch 541/1000\n",
      "10/10 [==============================] - 0s 282us/sample - loss: 2.0260\n",
      "Epoch 542/1000\n",
      "10/10 [==============================] - 0s 313us/sample - loss: 2.0254\n",
      "Epoch 543/1000\n",
      "10/10 [==============================] - 0s 476us/sample - loss: 2.0248\n",
      "Epoch 544/1000\n",
      "10/10 [==============================] - 0s 213us/sample - loss: 2.0243\n",
      "Epoch 545/1000\n",
      "10/10 [==============================] - 0s 424us/sample - loss: 2.0237\n",
      "Epoch 546/1000\n",
      "10/10 [==============================] - 0s 475us/sample - loss: 2.0231\n",
      "Epoch 547/1000\n",
      "10/10 [==============================] - 0s 359us/sample - loss: 2.0225\n",
      "Epoch 548/1000\n",
      "10/10 [==============================] - 0s 253us/sample - loss: 2.0220\n",
      "Epoch 549/1000\n",
      "10/10 [==============================] - 0s 285us/sample - loss: 2.0214\n",
      "Epoch 550/1000\n",
      "10/10 [==============================] - 0s 539us/sample - loss: 2.0208\n",
      "Epoch 551/1000\n",
      "10/10 [==============================] - 0s 293us/sample - loss: 2.0202\n",
      "Epoch 552/1000\n",
      "10/10 [==============================] - 0s 387us/sample - loss: 2.0197\n",
      "Epoch 553/1000\n",
      "10/10 [==============================] - 0s 226us/sample - loss: 2.0191\n",
      "Epoch 554/1000\n",
      "10/10 [==============================] - 0s 574us/sample - loss: 2.0185\n",
      "Epoch 555/1000\n",
      "10/10 [==============================] - 0s 303us/sample - loss: 2.0180\n",
      "Epoch 556/1000\n",
      "10/10 [==============================] - 0s 269us/sample - loss: 2.0174\n",
      "Epoch 557/1000\n",
      "10/10 [==============================] - 0s 484us/sample - loss: 2.0168\n",
      "Epoch 558/1000\n",
      "10/10 [==============================] - 0s 523us/sample - loss: 2.0163\n",
      "Epoch 559/1000\n",
      "10/10 [==============================] - 0s 959us/sample - loss: 2.0157\n",
      "Epoch 560/1000\n",
      "10/10 [==============================] - 0s 557us/sample - loss: 2.0151\n",
      "Epoch 561/1000\n",
      "10/10 [==============================] - 0s 316us/sample - loss: 2.0146\n",
      "Epoch 562/1000\n",
      "10/10 [==============================] - 0s 858us/sample - loss: 2.0140\n",
      "Epoch 563/1000\n",
      "10/10 [==============================] - 0s 500us/sample - loss: 2.0134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 564/1000\n",
      "10/10 [==============================] - 0s 362us/sample - loss: 2.0129\n",
      "Epoch 565/1000\n",
      "10/10 [==============================] - 0s 362us/sample - loss: 2.0123\n",
      "Epoch 566/1000\n",
      "10/10 [==============================] - 0s 358us/sample - loss: 2.0118\n",
      "Epoch 567/1000\n",
      "10/10 [==============================] - 0s 490us/sample - loss: 2.0112\n",
      "Epoch 568/1000\n",
      "10/10 [==============================] - 0s 244us/sample - loss: 2.0106\n",
      "Epoch 569/1000\n",
      "10/10 [==============================] - 0s 218us/sample - loss: 2.0101\n",
      "Epoch 570/1000\n",
      "10/10 [==============================] - 0s 526us/sample - loss: 2.0095\n",
      "Epoch 571/1000\n",
      "10/10 [==============================] - 0s 918us/sample - loss: 2.0090\n",
      "Epoch 572/1000\n",
      "10/10 [==============================] - 0s 583us/sample - loss: 2.0084\n",
      "Epoch 573/1000\n",
      "10/10 [==============================] - 0s 326us/sample - loss: 2.0079\n",
      "Epoch 574/1000\n",
      "10/10 [==============================] - 0s 315us/sample - loss: 2.0073\n",
      "Epoch 575/1000\n",
      "10/10 [==============================] - 0s 190us/sample - loss: 2.0067\n",
      "Epoch 576/1000\n",
      "10/10 [==============================] - 0s 170us/sample - loss: 2.0062\n",
      "Epoch 577/1000\n",
      "10/10 [==============================] - 0s 220us/sample - loss: 2.0056\n",
      "Epoch 578/1000\n",
      "10/10 [==============================] - 0s 219us/sample - loss: 2.0051\n",
      "Epoch 579/1000\n",
      "10/10 [==============================] - 0s 198us/sample - loss: 2.0045\n",
      "Epoch 580/1000\n",
      "10/10 [==============================] - 0s 845us/sample - loss: 2.0040\n",
      "Epoch 581/1000\n",
      "10/10 [==============================] - 0s 294us/sample - loss: 2.0034\n",
      "Epoch 582/1000\n",
      "10/10 [==============================] - 0s 217us/sample - loss: 2.0029\n",
      "Epoch 583/1000\n",
      "10/10 [==============================] - 0s 353us/sample - loss: 2.0023\n",
      "Epoch 584/1000\n",
      "10/10 [==============================] - 0s 229us/sample - loss: 2.0018\n",
      "Epoch 585/1000\n",
      "10/10 [==============================] - 0s 505us/sample - loss: 2.0012\n",
      "Epoch 586/1000\n",
      "10/10 [==============================] - 0s 440us/sample - loss: 2.0007\n",
      "Epoch 587/1000\n",
      "10/10 [==============================] - 0s 289us/sample - loss: 2.0002\n",
      "Epoch 588/1000\n",
      "10/10 [==============================] - 0s 269us/sample - loss: 1.9996\n",
      "Epoch 589/1000\n",
      "10/10 [==============================] - 0s 636us/sample - loss: 1.9991\n",
      "Epoch 590/1000\n",
      "10/10 [==============================] - 0s 656us/sample - loss: 1.9985\n",
      "Epoch 591/1000\n",
      "10/10 [==============================] - 0s 449us/sample - loss: 1.9980\n",
      "Epoch 592/1000\n",
      "10/10 [==============================] - 0s 310us/sample - loss: 1.9974\n",
      "Epoch 593/1000\n",
      "10/10 [==============================] - 0s 371us/sample - loss: 1.9969\n",
      "Epoch 594/1000\n",
      "10/10 [==============================] - 0s 258us/sample - loss: 1.9964\n",
      "Epoch 595/1000\n",
      "10/10 [==============================] - 0s 266us/sample - loss: 1.9958\n",
      "Epoch 596/1000\n",
      "10/10 [==============================] - 0s 239us/sample - loss: 1.9953\n",
      "Epoch 597/1000\n",
      "10/10 [==============================] - 0s 800us/sample - loss: 1.9948\n",
      "Epoch 598/1000\n",
      "10/10 [==============================] - 0s 356us/sample - loss: 1.9942\n",
      "Epoch 599/1000\n",
      "10/10 [==============================] - 0s 278us/sample - loss: 1.9937\n",
      "Epoch 600/1000\n",
      "10/10 [==============================] - 0s 276us/sample - loss: 1.9931\n",
      "Epoch 601/1000\n",
      "10/10 [==============================] - 0s 361us/sample - loss: 1.9926\n",
      "Epoch 602/1000\n",
      "10/10 [==============================] - 0s 250us/sample - loss: 1.9921\n",
      "Epoch 603/1000\n",
      "10/10 [==============================] - 0s 242us/sample - loss: 1.9915\n",
      "Epoch 604/1000\n",
      "10/10 [==============================] - 0s 412us/sample - loss: 1.9910\n",
      "Epoch 605/1000\n",
      "10/10 [==============================] - 0s 276us/sample - loss: 1.9905\n",
      "Epoch 606/1000\n",
      "10/10 [==============================] - 0s 343us/sample - loss: 1.9900\n",
      "Epoch 607/1000\n",
      "10/10 [==============================] - 0s 445us/sample - loss: 1.9894\n",
      "Epoch 608/1000\n",
      "10/10 [==============================] - 0s 293us/sample - loss: 1.9889\n",
      "Epoch 609/1000\n",
      "10/10 [==============================] - 0s 431us/sample - loss: 1.9884\n",
      "Epoch 610/1000\n",
      "10/10 [==============================] - 0s 247us/sample - loss: 1.9878\n",
      "Epoch 611/1000\n",
      "10/10 [==============================] - 0s 221us/sample - loss: 1.9873\n",
      "Epoch 612/1000\n",
      "10/10 [==============================] - 0s 213us/sample - loss: 1.9868\n",
      "Epoch 613/1000\n",
      "10/10 [==============================] - 0s 536us/sample - loss: 1.9863\n",
      "Epoch 614/1000\n",
      "10/10 [==============================] - 0s 457us/sample - loss: 1.9857\n",
      "Epoch 615/1000\n",
      "10/10 [==============================] - 0s 406us/sample - loss: 1.9852\n",
      "Epoch 616/1000\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 1.9847\n",
      "Epoch 617/1000\n",
      "10/10 [==============================] - 0s 216us/sample - loss: 1.9842\n",
      "Epoch 618/1000\n",
      "10/10 [==============================] - 0s 267us/sample - loss: 1.9837\n",
      "Epoch 619/1000\n",
      "10/10 [==============================] - 0s 250us/sample - loss: 1.9831\n",
      "Epoch 620/1000\n",
      "10/10 [==============================] - 0s 765us/sample - loss: 1.9826\n",
      "Epoch 621/1000\n",
      "10/10 [==============================] - 0s 330us/sample - loss: 1.9821\n",
      "Epoch 622/1000\n",
      "10/10 [==============================] - 0s 350us/sample - loss: 1.9816\n",
      "Epoch 623/1000\n",
      "10/10 [==============================] - 0s 238us/sample - loss: 1.9811\n",
      "Epoch 624/1000\n",
      "10/10 [==============================] - 0s 262us/sample - loss: 1.9805\n",
      "Epoch 625/1000\n",
      "10/10 [==============================] - 0s 223us/sample - loss: 1.9800\n",
      "Epoch 626/1000\n",
      "10/10 [==============================] - 0s 328us/sample - loss: 1.9795\n",
      "Epoch 627/1000\n",
      "10/10 [==============================] - 0s 234us/sample - loss: 1.9790\n",
      "Epoch 628/1000\n",
      "10/10 [==============================] - 0s 394us/sample - loss: 1.9785\n",
      "Epoch 629/1000\n",
      "10/10 [==============================] - 0s 271us/sample - loss: 1.9780\n",
      "Epoch 630/1000\n",
      "10/10 [==============================] - 0s 305us/sample - loss: 1.9775\n",
      "Epoch 631/1000\n",
      "10/10 [==============================] - 0s 190us/sample - loss: 1.9770\n",
      "Epoch 632/1000\n",
      "10/10 [==============================] - 0s 260us/sample - loss: 1.9764\n",
      "Epoch 633/1000\n",
      "10/10 [==============================] - 0s 321us/sample - loss: 1.9759\n",
      "Epoch 634/1000\n",
      "10/10 [==============================] - 0s 274us/sample - loss: 1.9754\n",
      "Epoch 635/1000\n",
      "10/10 [==============================] - 0s 238us/sample - loss: 1.9749\n",
      "Epoch 636/1000\n",
      "10/10 [==============================] - 0s 318us/sample - loss: 1.9744\n",
      "Epoch 637/1000\n",
      "10/10 [==============================] - 0s 454us/sample - loss: 1.9739\n",
      "Epoch 638/1000\n",
      "10/10 [==============================] - 0s 432us/sample - loss: 1.9734\n",
      "Epoch 639/1000\n",
      "10/10 [==============================] - 0s 368us/sample - loss: 1.9729\n",
      "Epoch 640/1000\n",
      "10/10 [==============================] - 0s 294us/sample - loss: 1.9724\n",
      "Epoch 641/1000\n",
      "10/10 [==============================] - 0s 294us/sample - loss: 1.9719\n",
      "Epoch 642/1000\n",
      "10/10 [==============================] - 0s 2ms/sample - loss: 1.9714\n",
      "Epoch 643/1000\n",
      "10/10 [==============================] - 0s 371us/sample - loss: 1.9709\n",
      "Epoch 644/1000\n",
      "10/10 [==============================] - 0s 230us/sample - loss: 1.9704\n",
      "Epoch 645/1000\n",
      "10/10 [==============================] - 0s 292us/sample - loss: 1.9699\n",
      "Epoch 646/1000\n",
      "10/10 [==============================] - 0s 155us/sample - loss: 1.9694\n",
      "Epoch 647/1000\n",
      "10/10 [==============================] - 0s 810us/sample - loss: 1.9689\n",
      "Epoch 648/1000\n",
      "10/10 [==============================] - 0s 875us/sample - loss: 1.9684\n",
      "Epoch 649/1000\n",
      "10/10 [==============================] - 0s 175us/sample - loss: 1.9679\n",
      "Epoch 650/1000\n",
      "10/10 [==============================] - 0s 188us/sample - loss: 1.9674\n",
      "Epoch 651/1000\n",
      "10/10 [==============================] - 0s 283us/sample - loss: 1.9669\n",
      "Epoch 652/1000\n",
      "10/10 [==============================] - 0s 566us/sample - loss: 1.9664\n",
      "Epoch 653/1000\n",
      "10/10 [==============================] - 0s 294us/sample - loss: 1.9659\n",
      "Epoch 654/1000\n",
      "10/10 [==============================] - 0s 297us/sample - loss: 1.9654\n",
      "Epoch 655/1000\n",
      "10/10 [==============================] - 0s 258us/sample - loss: 1.9649\n",
      "Epoch 656/1000\n",
      "10/10 [==============================] - 0s 596us/sample - loss: 1.9644\n",
      "Epoch 657/1000\n",
      "10/10 [==============================] - 0s 604us/sample - loss: 1.9639\n",
      "Epoch 658/1000\n",
      "10/10 [==============================] - 0s 275us/sample - loss: 1.9635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 659/1000\n",
      "10/10 [==============================] - 0s 253us/sample - loss: 1.9630\n",
      "Epoch 660/1000\n",
      "10/10 [==============================] - 0s 273us/sample - loss: 1.9625\n",
      "Epoch 661/1000\n",
      "10/10 [==============================] - 0s 403us/sample - loss: 1.9620\n",
      "Epoch 662/1000\n",
      "10/10 [==============================] - 0s 535us/sample - loss: 1.9615\n",
      "Epoch 663/1000\n",
      "10/10 [==============================] - 0s 340us/sample - loss: 1.9610\n",
      "Epoch 664/1000\n",
      "10/10 [==============================] - 0s 972us/sample - loss: 1.9605\n",
      "Epoch 665/1000\n",
      "10/10 [==============================] - 0s 387us/sample - loss: 1.9600\n",
      "Epoch 666/1000\n",
      "10/10 [==============================] - 0s 641us/sample - loss: 1.9596\n",
      "Epoch 667/1000\n",
      "10/10 [==============================] - 0s 310us/sample - loss: 1.9591\n",
      "Epoch 668/1000\n",
      "10/10 [==============================] - 0s 438us/sample - loss: 1.9586\n",
      "Epoch 669/1000\n",
      "10/10 [==============================] - 0s 642us/sample - loss: 1.9581\n",
      "Epoch 670/1000\n",
      "10/10 [==============================] - 0s 249us/sample - loss: 1.9576\n",
      "Epoch 671/1000\n",
      "10/10 [==============================] - 0s 673us/sample - loss: 1.9571\n",
      "Epoch 672/1000\n",
      "10/10 [==============================] - 0s 361us/sample - loss: 1.9567\n",
      "Epoch 673/1000\n",
      "10/10 [==============================] - 0s 231us/sample - loss: 1.9562\n",
      "Epoch 674/1000\n",
      "10/10 [==============================] - 0s 261us/sample - loss: 1.9557\n",
      "Epoch 675/1000\n",
      "10/10 [==============================] - 0s 691us/sample - loss: 1.9552\n",
      "Epoch 676/1000\n",
      "10/10 [==============================] - 0s 467us/sample - loss: 1.9548\n",
      "Epoch 677/1000\n",
      "10/10 [==============================] - 0s 308us/sample - loss: 1.9543\n",
      "Epoch 678/1000\n",
      "10/10 [==============================] - 0s 276us/sample - loss: 1.9538\n",
      "Epoch 679/1000\n",
      "10/10 [==============================] - 0s 380us/sample - loss: 1.9533\n",
      "Epoch 680/1000\n",
      "10/10 [==============================] - 0s 416us/sample - loss: 1.9529\n",
      "Epoch 681/1000\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 1.9524\n",
      "Epoch 682/1000\n",
      "10/10 [==============================] - 0s 345us/sample - loss: 1.9519\n",
      "Epoch 683/1000\n",
      "10/10 [==============================] - 0s 369us/sample - loss: 1.9514\n",
      "Epoch 684/1000\n",
      "10/10 [==============================] - 0s 195us/sample - loss: 1.9510\n",
      "Epoch 685/1000\n",
      "10/10 [==============================] - 0s 862us/sample - loss: 1.9505\n",
      "Epoch 686/1000\n",
      "10/10 [==============================] - 0s 441us/sample - loss: 1.9500\n",
      "Epoch 687/1000\n",
      "10/10 [==============================] - 0s 247us/sample - loss: 1.9496\n",
      "Epoch 688/1000\n",
      "10/10 [==============================] - 0s 243us/sample - loss: 1.9491\n",
      "Epoch 689/1000\n",
      "10/10 [==============================] - 0s 239us/sample - loss: 1.9486\n",
      "Epoch 690/1000\n",
      "10/10 [==============================] - 0s 249us/sample - loss: 1.9482\n",
      "Epoch 691/1000\n",
      "10/10 [==============================] - 0s 318us/sample - loss: 1.9477\n",
      "Epoch 692/1000\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 1.9472\n",
      "Epoch 693/1000\n",
      "10/10 [==============================] - 0s 441us/sample - loss: 1.9468\n",
      "Epoch 694/1000\n",
      "10/10 [==============================] - 0s 280us/sample - loss: 1.9463\n",
      "Epoch 695/1000\n",
      "10/10 [==============================] - 0s 266us/sample - loss: 1.9459\n",
      "Epoch 696/1000\n",
      "10/10 [==============================] - 0s 857us/sample - loss: 1.9454\n",
      "Epoch 697/1000\n",
      "10/10 [==============================] - 0s 287us/sample - loss: 1.9449\n",
      "Epoch 698/1000\n",
      "10/10 [==============================] - 0s 233us/sample - loss: 1.9445\n",
      "Epoch 699/1000\n",
      "10/10 [==============================] - 0s 490us/sample - loss: 1.9440\n",
      "Epoch 700/1000\n",
      "10/10 [==============================] - 0s 580us/sample - loss: 1.9436\n",
      "Epoch 701/1000\n",
      "10/10 [==============================] - 0s 304us/sample - loss: 1.9431\n",
      "Epoch 702/1000\n",
      "10/10 [==============================] - 0s 415us/sample - loss: 1.9426\n",
      "Epoch 703/1000\n",
      "10/10 [==============================] - 0s 402us/sample - loss: 1.9422\n",
      "Epoch 704/1000\n",
      "10/10 [==============================] - 0s 420us/sample - loss: 1.9417\n",
      "Epoch 705/1000\n",
      "10/10 [==============================] - 0s 339us/sample - loss: 1.9413\n",
      "Epoch 706/1000\n",
      "10/10 [==============================] - 0s 395us/sample - loss: 1.9408\n",
      "Epoch 707/1000\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 1.9404\n",
      "Epoch 708/1000\n",
      "10/10 [==============================] - 0s 228us/sample - loss: 1.9399\n",
      "Epoch 709/1000\n",
      "10/10 [==============================] - 0s 238us/sample - loss: 1.9395\n",
      "Epoch 710/1000\n",
      "10/10 [==============================] - 0s 221us/sample - loss: 1.9390\n",
      "Epoch 711/1000\n",
      "10/10 [==============================] - 0s 278us/sample - loss: 1.9386\n",
      "Epoch 712/1000\n",
      "10/10 [==============================] - 0s 340us/sample - loss: 1.9381\n",
      "Epoch 713/1000\n",
      "10/10 [==============================] - 0s 737us/sample - loss: 1.9377\n",
      "Epoch 714/1000\n",
      "10/10 [==============================] - 0s 303us/sample - loss: 1.9372\n",
      "Epoch 715/1000\n",
      "10/10 [==============================] - 0s 350us/sample - loss: 1.9368\n",
      "Epoch 716/1000\n",
      "10/10 [==============================] - 0s 332us/sample - loss: 1.9363\n",
      "Epoch 717/1000\n",
      "10/10 [==============================] - 0s 326us/sample - loss: 1.9359\n",
      "Epoch 718/1000\n",
      "10/10 [==============================] - 0s 579us/sample - loss: 1.9354\n",
      "Epoch 719/1000\n",
      "10/10 [==============================] - 0s 462us/sample - loss: 1.9350\n",
      "Epoch 720/1000\n",
      "10/10 [==============================] - 0s 351us/sample - loss: 1.9346\n",
      "Epoch 721/1000\n",
      "10/10 [==============================] - 0s 828us/sample - loss: 1.9341\n",
      "Epoch 722/1000\n",
      "10/10 [==============================] - 0s 467us/sample - loss: 1.9337\n",
      "Epoch 723/1000\n",
      "10/10 [==============================] - 0s 308us/sample - loss: 1.9332\n",
      "Epoch 724/1000\n",
      "10/10 [==============================] - 0s 544us/sample - loss: 1.9328\n",
      "Epoch 725/1000\n",
      "10/10 [==============================] - 0s 251us/sample - loss: 1.9324\n",
      "Epoch 726/1000\n",
      "10/10 [==============================] - 0s 220us/sample - loss: 1.9319\n",
      "Epoch 727/1000\n",
      "10/10 [==============================] - 0s 318us/sample - loss: 1.9315\n",
      "Epoch 728/1000\n",
      "10/10 [==============================] - 0s 304us/sample - loss: 1.9310\n",
      "Epoch 729/1000\n",
      "10/10 [==============================] - 0s 235us/sample - loss: 1.9306\n",
      "Epoch 730/1000\n",
      "10/10 [==============================] - 0s 644us/sample - loss: 1.9302\n",
      "Epoch 731/1000\n",
      "10/10 [==============================] - 0s 246us/sample - loss: 1.9297\n",
      "Epoch 732/1000\n",
      "10/10 [==============================] - 0s 322us/sample - loss: 1.9293\n",
      "Epoch 733/1000\n",
      "10/10 [==============================] - 0s 298us/sample - loss: 1.9289\n",
      "Epoch 734/1000\n",
      "10/10 [==============================] - 0s 377us/sample - loss: 1.9284\n",
      "Epoch 735/1000\n",
      "10/10 [==============================] - 0s 327us/sample - loss: 1.9280\n",
      "Epoch 736/1000\n",
      "10/10 [==============================] - 0s 325us/sample - loss: 1.9276\n",
      "Epoch 737/1000\n",
      "10/10 [==============================] - 0s 357us/sample - loss: 1.9271\n",
      "Epoch 738/1000\n",
      "10/10 [==============================] - 0s 775us/sample - loss: 1.9267\n",
      "Epoch 739/1000\n",
      "10/10 [==============================] - 0s 247us/sample - loss: 1.9263\n",
      "Epoch 740/1000\n",
      "10/10 [==============================] - 0s 256us/sample - loss: 1.9259\n",
      "Epoch 741/1000\n",
      "10/10 [==============================] - 0s 279us/sample - loss: 1.9254\n",
      "Epoch 742/1000\n",
      "10/10 [==============================] - 0s 304us/sample - loss: 1.9250\n",
      "Epoch 743/1000\n",
      "10/10 [==============================] - 0s 436us/sample - loss: 1.9246\n",
      "Epoch 744/1000\n",
      "10/10 [==============================] - 0s 278us/sample - loss: 1.9242\n",
      "Epoch 745/1000\n",
      "10/10 [==============================] - 0s 471us/sample - loss: 1.9237\n",
      "Epoch 746/1000\n",
      "10/10 [==============================] - 0s 207us/sample - loss: 1.9233\n",
      "Epoch 747/1000\n",
      "10/10 [==============================] - 0s 212us/sample - loss: 1.9229\n",
      "Epoch 748/1000\n",
      "10/10 [==============================] - 0s 885us/sample - loss: 1.9225\n",
      "Epoch 749/1000\n",
      "10/10 [==============================] - 0s 260us/sample - loss: 1.9220\n",
      "Epoch 750/1000\n",
      "10/10 [==============================] - 0s 435us/sample - loss: 1.9216\n",
      "Epoch 751/1000\n",
      "10/10 [==============================] - 0s 308us/sample - loss: 1.9212\n",
      "Epoch 752/1000\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 1.9208\n",
      "Epoch 753/1000\n",
      "10/10 [==============================] - 0s 515us/sample - loss: 1.9204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 754/1000\n",
      "10/10 [==============================] - 0s 268us/sample - loss: 1.9200\n",
      "Epoch 755/1000\n",
      "10/10 [==============================] - 0s 294us/sample - loss: 1.9195\n",
      "Epoch 756/1000\n",
      "10/10 [==============================] - 0s 979us/sample - loss: 1.9191\n",
      "Epoch 757/1000\n",
      "10/10 [==============================] - 0s 475us/sample - loss: 1.9187\n",
      "Epoch 758/1000\n",
      "10/10 [==============================] - 0s 317us/sample - loss: 1.9183\n",
      "Epoch 759/1000\n",
      "10/10 [==============================] - 0s 317us/sample - loss: 1.9179\n",
      "Epoch 760/1000\n",
      "10/10 [==============================] - 0s 281us/sample - loss: 1.9175\n",
      "Epoch 761/1000\n",
      "10/10 [==============================] - 0s 503us/sample - loss: 1.9171\n",
      "Epoch 762/1000\n",
      "10/10 [==============================] - 0s 2ms/sample - loss: 1.9167\n",
      "Epoch 763/1000\n",
      "10/10 [==============================] - 0s 418us/sample - loss: 1.9162\n",
      "Epoch 764/1000\n",
      "10/10 [==============================] - 0s 298us/sample - loss: 1.9158\n",
      "Epoch 765/1000\n",
      "10/10 [==============================] - 0s 305us/sample - loss: 1.9154\n",
      "Epoch 766/1000\n",
      "10/10 [==============================] - 0s 245us/sample - loss: 1.9150\n",
      "Epoch 767/1000\n",
      "10/10 [==============================] - 0s 449us/sample - loss: 1.9146\n",
      "Epoch 768/1000\n",
      "10/10 [==============================] - 0s 283us/sample - loss: 1.9142\n",
      "Epoch 769/1000\n",
      "10/10 [==============================] - 0s 194us/sample - loss: 1.9138\n",
      "Epoch 770/1000\n",
      "10/10 [==============================] - 0s 203us/sample - loss: 1.9134\n",
      "Epoch 771/1000\n",
      "10/10 [==============================] - 0s 213us/sample - loss: 1.9130\n",
      "Epoch 772/1000\n",
      "10/10 [==============================] - 0s 573us/sample - loss: 1.9126\n",
      "Epoch 773/1000\n",
      "10/10 [==============================] - 0s 349us/sample - loss: 1.9122\n",
      "Epoch 774/1000\n",
      "10/10 [==============================] - 0s 443us/sample - loss: 1.9118\n",
      "Epoch 775/1000\n",
      "10/10 [==============================] - 0s 263us/sample - loss: 1.9114\n",
      "Epoch 776/1000\n",
      "10/10 [==============================] - 0s 362us/sample - loss: 1.9110\n",
      "Epoch 777/1000\n",
      "10/10 [==============================] - 0s 293us/sample - loss: 1.9106\n",
      "Epoch 778/1000\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 1.9102\n",
      "Epoch 779/1000\n",
      "10/10 [==============================] - 0s 265us/sample - loss: 1.9098\n",
      "Epoch 780/1000\n",
      "10/10 [==============================] - 0s 258us/sample - loss: 1.9094\n",
      "Epoch 781/1000\n",
      "10/10 [==============================] - 0s 316us/sample - loss: 1.9090\n",
      "Epoch 782/1000\n",
      "10/10 [==============================] - 0s 767us/sample - loss: 1.9086\n",
      "Epoch 783/1000\n",
      "10/10 [==============================] - 0s 763us/sample - loss: 1.9082\n",
      "Epoch 784/1000\n",
      "10/10 [==============================] - 0s 334us/sample - loss: 1.9078\n",
      "Epoch 785/1000\n",
      "10/10 [==============================] - 0s 321us/sample - loss: 1.9074\n",
      "Epoch 786/1000\n",
      "10/10 [==============================] - 0s 741us/sample - loss: 1.9070\n",
      "Epoch 787/1000\n",
      "10/10 [==============================] - 0s 330us/sample - loss: 1.9066\n",
      "Epoch 788/1000\n",
      "10/10 [==============================] - 0s 458us/sample - loss: 1.9062\n",
      "Epoch 789/1000\n",
      "10/10 [==============================] - 0s 514us/sample - loss: 1.9059\n",
      "Epoch 790/1000\n",
      "10/10 [==============================] - 0s 384us/sample - loss: 1.9055\n",
      "Epoch 791/1000\n",
      "10/10 [==============================] - 0s 343us/sample - loss: 1.9051\n",
      "Epoch 792/1000\n",
      "10/10 [==============================] - 0s 470us/sample - loss: 1.9047\n",
      "Epoch 793/1000\n",
      "10/10 [==============================] - 0s 255us/sample - loss: 1.9043\n",
      "Epoch 794/1000\n",
      "10/10 [==============================] - 0s 318us/sample - loss: 1.9039\n",
      "Epoch 795/1000\n",
      "10/10 [==============================] - 0s 243us/sample - loss: 1.9035\n",
      "Epoch 796/1000\n",
      "10/10 [==============================] - 0s 253us/sample - loss: 1.9031\n",
      "Epoch 797/1000\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 1.9028\n",
      "Epoch 798/1000\n",
      "10/10 [==============================] - 0s 324us/sample - loss: 1.9024\n",
      "Epoch 799/1000\n",
      "10/10 [==============================] - 0s 293us/sample - loss: 1.9020\n",
      "Epoch 800/1000\n",
      "10/10 [==============================] - 0s 883us/sample - loss: 1.9016\n",
      "Epoch 801/1000\n",
      "10/10 [==============================] - 0s 508us/sample - loss: 1.9012\n",
      "Epoch 802/1000\n",
      "10/10 [==============================] - 0s 314us/sample - loss: 1.9009\n",
      "Epoch 803/1000\n",
      "10/10 [==============================] - 0s 241us/sample - loss: 1.9005\n",
      "Epoch 804/1000\n",
      "10/10 [==============================] - 0s 241us/sample - loss: 1.9001\n",
      "Epoch 805/1000\n",
      "10/10 [==============================] - 0s 907us/sample - loss: 1.8997\n",
      "Epoch 806/1000\n",
      "10/10 [==============================] - 0s 407us/sample - loss: 1.8993\n",
      "Epoch 807/1000\n",
      "10/10 [==============================] - 0s 280us/sample - loss: 1.8990\n",
      "Epoch 808/1000\n",
      "10/10 [==============================] - 0s 293us/sample - loss: 1.8986\n",
      "Epoch 809/1000\n",
      "10/10 [==============================] - 0s 257us/sample - loss: 1.8982\n",
      "Epoch 810/1000\n",
      "10/10 [==============================] - 0s 273us/sample - loss: 1.8978\n",
      "Epoch 811/1000\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 1.8975\n",
      "Epoch 812/1000\n",
      "10/10 [==============================] - 0s 305us/sample - loss: 1.8971\n",
      "Epoch 813/1000\n",
      "10/10 [==============================] - 0s 316us/sample - loss: 1.8967\n",
      "Epoch 814/1000\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 1.8964\n",
      "Epoch 815/1000\n",
      "10/10 [==============================] - 0s 302us/sample - loss: 1.8960\n",
      "Epoch 816/1000\n",
      "10/10 [==============================] - 0s 420us/sample - loss: 1.8956\n",
      "Epoch 817/1000\n",
      "10/10 [==============================] - 0s 290us/sample - loss: 1.8952\n",
      "Epoch 818/1000\n",
      "10/10 [==============================] - 0s 500us/sample - loss: 1.8949\n",
      "Epoch 819/1000\n",
      "10/10 [==============================] - 0s 255us/sample - loss: 1.8945\n",
      "Epoch 820/1000\n",
      "10/10 [==============================] - 0s 308us/sample - loss: 1.8941\n",
      "Epoch 821/1000\n",
      "10/10 [==============================] - 0s 299us/sample - loss: 1.8938\n",
      "Epoch 822/1000\n",
      "10/10 [==============================] - 0s 231us/sample - loss: 1.8934\n",
      "Epoch 823/1000\n",
      "10/10 [==============================] - 0s 746us/sample - loss: 1.8930\n",
      "Epoch 824/1000\n",
      "10/10 [==============================] - 0s 306us/sample - loss: 1.8927\n",
      "Epoch 825/1000\n",
      "10/10 [==============================] - 0s 295us/sample - loss: 1.8923\n",
      "Epoch 826/1000\n",
      "10/10 [==============================] - 0s 305us/sample - loss: 1.8920\n",
      "Epoch 827/1000\n",
      "10/10 [==============================] - 0s 328us/sample - loss: 1.8916\n",
      "Epoch 828/1000\n",
      "10/10 [==============================] - 0s 228us/sample - loss: 1.8912\n",
      "Epoch 829/1000\n",
      "10/10 [==============================] - 0s 336us/sample - loss: 1.8909\n",
      "Epoch 830/1000\n",
      "10/10 [==============================] - 0s 678us/sample - loss: 1.8905\n",
      "Epoch 831/1000\n",
      "10/10 [==============================] - 0s 915us/sample - loss: 1.8902\n",
      "Epoch 832/1000\n",
      "10/10 [==============================] - 0s 214us/sample - loss: 1.8898\n",
      "Epoch 833/1000\n",
      "10/10 [==============================] - 0s 290us/sample - loss: 1.8894\n",
      "Epoch 834/1000\n",
      "10/10 [==============================] - 0s 270us/sample - loss: 1.8891\n",
      "Epoch 835/1000\n",
      "10/10 [==============================] - 0s 279us/sample - loss: 1.8887\n",
      "Epoch 836/1000\n",
      "10/10 [==============================] - 0s 408us/sample - loss: 1.8884\n",
      "Epoch 837/1000\n",
      "10/10 [==============================] - 0s 237us/sample - loss: 1.8880\n",
      "Epoch 838/1000\n",
      "10/10 [==============================] - 0s 317us/sample - loss: 1.8877\n",
      "Epoch 839/1000\n",
      "10/10 [==============================] - 0s 455us/sample - loss: 1.8873\n",
      "Epoch 840/1000\n",
      "10/10 [==============================] - 0s 239us/sample - loss: 1.8870\n",
      "Epoch 841/1000\n",
      "10/10 [==============================] - 0s 326us/sample - loss: 1.8866\n",
      "Epoch 842/1000\n",
      "10/10 [==============================] - 0s 770us/sample - loss: 1.8863\n",
      "Epoch 843/1000\n",
      "10/10 [==============================] - 0s 301us/sample - loss: 1.8859\n",
      "Epoch 844/1000\n",
      "10/10 [==============================] - 0s 212us/sample - loss: 1.8856\n",
      "Epoch 845/1000\n",
      "10/10 [==============================] - 0s 236us/sample - loss: 1.8852\n",
      "Epoch 846/1000\n",
      "10/10 [==============================] - 0s 685us/sample - loss: 1.8849\n",
      "Epoch 847/1000\n",
      "10/10 [==============================] - 0s 383us/sample - loss: 1.8845\n",
      "Epoch 848/1000\n",
      "10/10 [==============================] - 0s 353us/sample - loss: 1.8842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 849/1000\n",
      "10/10 [==============================] - 0s 491us/sample - loss: 1.8838\n",
      "Epoch 850/1000\n",
      "10/10 [==============================] - 0s 412us/sample - loss: 1.8835\n",
      "Epoch 851/1000\n",
      "10/10 [==============================] - 0s 343us/sample - loss: 1.8832\n",
      "Epoch 852/1000\n",
      "10/10 [==============================] - 0s 246us/sample - loss: 1.8828\n",
      "Epoch 853/1000\n",
      "10/10 [==============================] - 0s 345us/sample - loss: 1.8825\n",
      "Epoch 854/1000\n",
      "10/10 [==============================] - 0s 305us/sample - loss: 1.8821\n",
      "Epoch 855/1000\n",
      "10/10 [==============================] - 0s 523us/sample - loss: 1.8818\n",
      "Epoch 856/1000\n",
      "10/10 [==============================] - 0s 343us/sample - loss: 1.8815\n",
      "Epoch 857/1000\n",
      "10/10 [==============================] - 0s 209us/sample - loss: 1.8811\n",
      "Epoch 858/1000\n",
      "10/10 [==============================] - 0s 924us/sample - loss: 1.8808\n",
      "Epoch 859/1000\n",
      "10/10 [==============================] - 0s 468us/sample - loss: 1.8804\n",
      "Epoch 860/1000\n",
      "10/10 [==============================] - 0s 608us/sample - loss: 1.8801\n",
      "Epoch 861/1000\n",
      "10/10 [==============================] - 0s 398us/sample - loss: 1.8798\n",
      "Epoch 862/1000\n",
      "10/10 [==============================] - 0s 477us/sample - loss: 1.8794\n",
      "Epoch 863/1000\n",
      "10/10 [==============================] - 0s 644us/sample - loss: 1.8791\n",
      "Epoch 864/1000\n",
      "10/10 [==============================] - 0s 244us/sample - loss: 1.8788\n",
      "Epoch 865/1000\n",
      "10/10 [==============================] - 0s 863us/sample - loss: 1.8784\n",
      "Epoch 866/1000\n",
      "10/10 [==============================] - 0s 442us/sample - loss: 1.8781\n",
      "Epoch 867/1000\n",
      "10/10 [==============================] - 0s 302us/sample - loss: 1.8778\n",
      "Epoch 868/1000\n",
      "10/10 [==============================] - 0s 747us/sample - loss: 1.8775\n",
      "Epoch 869/1000\n",
      "10/10 [==============================] - 0s 334us/sample - loss: 1.8771\n",
      "Epoch 870/1000\n",
      "10/10 [==============================] - 0s 204us/sample - loss: 1.8768\n",
      "Epoch 871/1000\n",
      "10/10 [==============================] - 0s 575us/sample - loss: 1.8765\n",
      "Epoch 872/1000\n",
      "10/10 [==============================] - 0s 298us/sample - loss: 1.8761\n",
      "Epoch 873/1000\n",
      "10/10 [==============================] - 0s 391us/sample - loss: 1.8758\n",
      "Epoch 874/1000\n",
      "10/10 [==============================] - 0s 374us/sample - loss: 1.8755\n",
      "Epoch 875/1000\n",
      "10/10 [==============================] - 0s 895us/sample - loss: 1.8752\n",
      "Epoch 876/1000\n",
      "10/10 [==============================] - 0s 229us/sample - loss: 1.8748\n",
      "Epoch 877/1000\n",
      "10/10 [==============================] - 0s 277us/sample - loss: 1.8745\n",
      "Epoch 878/1000\n",
      "10/10 [==============================] - 0s 514us/sample - loss: 1.8742\n",
      "Epoch 879/1000\n",
      "10/10 [==============================] - 0s 286us/sample - loss: 1.8739\n",
      "Epoch 880/1000\n",
      "10/10 [==============================] - 0s 368us/sample - loss: 1.8736\n",
      "Epoch 881/1000\n",
      "10/10 [==============================] - 0s 287us/sample - loss: 1.8732\n",
      "Epoch 882/1000\n",
      "10/10 [==============================] - 0s 514us/sample - loss: 1.8729\n",
      "Epoch 883/1000\n",
      "10/10 [==============================] - 0s 250us/sample - loss: 1.8726\n",
      "Epoch 884/1000\n",
      "10/10 [==============================] - 0s 495us/sample - loss: 1.8723\n",
      "Epoch 885/1000\n",
      "10/10 [==============================] - 0s 283us/sample - loss: 1.8720\n",
      "Epoch 886/1000\n",
      "10/10 [==============================] - 0s 276us/sample - loss: 1.8716\n",
      "Epoch 887/1000\n",
      "10/10 [==============================] - 0s 393us/sample - loss: 1.8713\n",
      "Epoch 888/1000\n",
      "10/10 [==============================] - 0s 482us/sample - loss: 1.8710\n",
      "Epoch 889/1000\n",
      "10/10 [==============================] - 0s 474us/sample - loss: 1.8707\n",
      "Epoch 890/1000\n",
      "10/10 [==============================] - 0s 264us/sample - loss: 1.8704\n",
      "Epoch 891/1000\n",
      "10/10 [==============================] - 0s 290us/sample - loss: 1.8701\n",
      "Epoch 892/1000\n",
      "10/10 [==============================] - 0s 245us/sample - loss: 1.8698\n",
      "Epoch 893/1000\n",
      "10/10 [==============================] - 0s 377us/sample - loss: 1.8695\n",
      "Epoch 894/1000\n",
      "10/10 [==============================] - 0s 556us/sample - loss: 1.8691\n",
      "Epoch 895/1000\n",
      "10/10 [==============================] - 0s 316us/sample - loss: 1.8688\n",
      "Epoch 896/1000\n",
      "10/10 [==============================] - 0s 508us/sample - loss: 1.8685\n",
      "Epoch 897/1000\n",
      "10/10 [==============================] - 0s 251us/sample - loss: 1.8682\n",
      "Epoch 898/1000\n",
      "10/10 [==============================] - 0s 187us/sample - loss: 1.8679\n",
      "Epoch 899/1000\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 1.8676\n",
      "Epoch 900/1000\n",
      "10/10 [==============================] - 0s 695us/sample - loss: 1.8673\n",
      "Epoch 901/1000\n",
      "10/10 [==============================] - 0s 236us/sample - loss: 1.8670\n",
      "Epoch 902/1000\n",
      "10/10 [==============================] - 0s 294us/sample - loss: 1.8667\n",
      "Epoch 903/1000\n",
      "10/10 [==============================] - 0s 426us/sample - loss: 1.8664\n",
      "Epoch 904/1000\n",
      "10/10 [==============================] - 0s 829us/sample - loss: 1.8661\n",
      "Epoch 905/1000\n",
      "10/10 [==============================] - 0s 232us/sample - loss: 1.8658\n",
      "Epoch 906/1000\n",
      "10/10 [==============================] - 0s 296us/sample - loss: 1.8655\n",
      "Epoch 907/1000\n",
      "10/10 [==============================] - 0s 307us/sample - loss: 1.8652\n",
      "Epoch 908/1000\n",
      "10/10 [==============================] - 0s 260us/sample - loss: 1.8649\n",
      "Epoch 909/1000\n",
      "10/10 [==============================] - 0s 314us/sample - loss: 1.8646\n",
      "Epoch 910/1000\n",
      "10/10 [==============================] - 0s 995us/sample - loss: 1.8643\n",
      "Epoch 911/1000\n",
      "10/10 [==============================] - 0s 449us/sample - loss: 1.8640\n",
      "Epoch 912/1000\n",
      "10/10 [==============================] - 0s 2ms/sample - loss: 1.8637\n",
      "Epoch 913/1000\n",
      "10/10 [==============================] - 0s 368us/sample - loss: 1.8634\n",
      "Epoch 914/1000\n",
      "10/10 [==============================] - 0s 375us/sample - loss: 1.8631\n",
      "Epoch 915/1000\n",
      "10/10 [==============================] - 0s 239us/sample - loss: 1.8628\n",
      "Epoch 916/1000\n",
      "10/10 [==============================] - 0s 202us/sample - loss: 1.8625\n",
      "Epoch 917/1000\n",
      "10/10 [==============================] - 0s 782us/sample - loss: 1.8622\n",
      "Epoch 918/1000\n",
      "10/10 [==============================] - 0s 360us/sample - loss: 1.8619\n",
      "Epoch 919/1000\n",
      "10/10 [==============================] - 0s 348us/sample - loss: 1.8616\n",
      "Epoch 920/1000\n",
      "10/10 [==============================] - 0s 251us/sample - loss: 1.8613\n",
      "Epoch 921/1000\n",
      "10/10 [==============================] - 0s 472us/sample - loss: 1.8611\n",
      "Epoch 922/1000\n",
      "10/10 [==============================] - 0s 377us/sample - loss: 1.8608\n",
      "Epoch 923/1000\n",
      "10/10 [==============================] - 0s 396us/sample - loss: 1.8605\n",
      "Epoch 924/1000\n",
      "10/10 [==============================] - 0s 283us/sample - loss: 1.8602\n",
      "Epoch 925/1000\n",
      "10/10 [==============================] - 0s 773us/sample - loss: 1.8599\n",
      "Epoch 926/1000\n",
      "10/10 [==============================] - 0s 236us/sample - loss: 1.8596\n",
      "Epoch 927/1000\n",
      "10/10 [==============================] - 0s 259us/sample - loss: 1.8593\n",
      "Epoch 928/1000\n",
      "10/10 [==============================] - 0s 402us/sample - loss: 1.8591\n",
      "Epoch 929/1000\n",
      "10/10 [==============================] - 0s 381us/sample - loss: 1.8588\n",
      "Epoch 930/1000\n",
      "10/10 [==============================] - 0s 382us/sample - loss: 1.8585\n",
      "Epoch 931/1000\n",
      "10/10 [==============================] - 0s 416us/sample - loss: 1.8582\n",
      "Epoch 932/1000\n",
      "10/10 [==============================] - 0s 268us/sample - loss: 1.8579\n",
      "Epoch 933/1000\n",
      "10/10 [==============================] - 0s 248us/sample - loss: 1.8576\n",
      "Epoch 934/1000\n",
      "10/10 [==============================] - 0s 738us/sample - loss: 1.8574\n",
      "Epoch 935/1000\n",
      "10/10 [==============================] - 0s 466us/sample - loss: 1.8571\n",
      "Epoch 936/1000\n",
      "10/10 [==============================] - 0s 320us/sample - loss: 1.8568\n",
      "Epoch 937/1000\n",
      "10/10 [==============================] - 0s 294us/sample - loss: 1.8565\n",
      "Epoch 938/1000\n",
      "10/10 [==============================] - 0s 302us/sample - loss: 1.8563\n",
      "Epoch 939/1000\n",
      "10/10 [==============================] - 0s 194us/sample - loss: 1.8560\n",
      "Epoch 940/1000\n",
      "10/10 [==============================] - 0s 402us/sample - loss: 1.8557\n",
      "Epoch 941/1000\n",
      "10/10 [==============================] - 0s 657us/sample - loss: 1.8554\n",
      "Epoch 942/1000\n",
      "10/10 [==============================] - 0s 380us/sample - loss: 1.8552\n",
      "Epoch 943/1000\n",
      "10/10 [==============================] - 0s 301us/sample - loss: 1.8549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 944/1000\n",
      "10/10 [==============================] - 0s 424us/sample - loss: 1.8546\n",
      "Epoch 945/1000\n",
      "10/10 [==============================] - 0s 200us/sample - loss: 1.8543\n",
      "Epoch 946/1000\n",
      "10/10 [==============================] - 0s 422us/sample - loss: 1.8541\n",
      "Epoch 947/1000\n",
      "10/10 [==============================] - 0s 333us/sample - loss: 1.8538\n",
      "Epoch 948/1000\n",
      "10/10 [==============================] - 0s 295us/sample - loss: 1.8535\n",
      "Epoch 949/1000\n",
      "10/10 [==============================] - 0s 361us/sample - loss: 1.8533\n",
      "Epoch 950/1000\n",
      "10/10 [==============================] - 0s 498us/sample - loss: 1.8530\n",
      "Epoch 951/1000\n",
      "10/10 [==============================] - 0s 347us/sample - loss: 1.8527\n",
      "Epoch 952/1000\n",
      "10/10 [==============================] - 0s 792us/sample - loss: 1.8525\n",
      "Epoch 953/1000\n",
      "10/10 [==============================] - 0s 297us/sample - loss: 1.8522\n",
      "Epoch 954/1000\n",
      "10/10 [==============================] - 0s 748us/sample - loss: 1.8519\n",
      "Epoch 955/1000\n",
      "10/10 [==============================] - 0s 177us/sample - loss: 1.8517\n",
      "Epoch 956/1000\n",
      "10/10 [==============================] - 0s 196us/sample - loss: 1.8514\n",
      "Epoch 957/1000\n",
      "10/10 [==============================] - 0s 208us/sample - loss: 1.8511\n",
      "Epoch 958/1000\n",
      "10/10 [==============================] - 0s 527us/sample - loss: 1.8509\n",
      "Epoch 959/1000\n",
      "10/10 [==============================] - 0s 433us/sample - loss: 1.8506\n",
      "Epoch 960/1000\n",
      "10/10 [==============================] - 0s 353us/sample - loss: 1.8504\n",
      "Epoch 961/1000\n",
      "10/10 [==============================] - 0s 614us/sample - loss: 1.8501\n",
      "Epoch 962/1000\n",
      "10/10 [==============================] - 0s 323us/sample - loss: 1.8498\n",
      "Epoch 963/1000\n",
      "10/10 [==============================] - 0s 345us/sample - loss: 1.8496\n",
      "Epoch 964/1000\n",
      "10/10 [==============================] - 0s 718us/sample - loss: 1.8493\n",
      "Epoch 965/1000\n",
      "10/10 [==============================] - 0s 311us/sample - loss: 1.8491\n",
      "Epoch 966/1000\n",
      "10/10 [==============================] - 0s 537us/sample - loss: 1.8488\n",
      "Epoch 967/1000\n",
      "10/10 [==============================] - 0s 259us/sample - loss: 1.8486\n",
      "Epoch 968/1000\n",
      "10/10 [==============================] - 0s 265us/sample - loss: 1.8483\n",
      "Epoch 969/1000\n",
      "10/10 [==============================] - 0s 382us/sample - loss: 1.8481\n",
      "Epoch 970/1000\n",
      "10/10 [==============================] - 0s 261us/sample - loss: 1.8478\n",
      "Epoch 971/1000\n",
      "10/10 [==============================] - 0s 313us/sample - loss: 1.8475\n",
      "Epoch 972/1000\n",
      "10/10 [==============================] - 0s 594us/sample - loss: 1.8473\n",
      "Epoch 973/1000\n",
      "10/10 [==============================] - 0s 571us/sample - loss: 1.8470\n",
      "Epoch 974/1000\n",
      "10/10 [==============================] - 0s 660us/sample - loss: 1.8468\n",
      "Epoch 975/1000\n",
      "10/10 [==============================] - 0s 381us/sample - loss: 1.8465\n",
      "Epoch 976/1000\n",
      "10/10 [==============================] - 0s 186us/sample - loss: 1.8463\n",
      "Epoch 977/1000\n",
      "10/10 [==============================] - 0s 224us/sample - loss: 1.8461\n",
      "Epoch 978/1000\n",
      "10/10 [==============================] - 0s 987us/sample - loss: 1.8458\n",
      "Epoch 979/1000\n",
      "10/10 [==============================] - 0s 367us/sample - loss: 1.8456\n",
      "Epoch 980/1000\n",
      "10/10 [==============================] - 0s 260us/sample - loss: 1.8453\n",
      "Epoch 981/1000\n",
      "10/10 [==============================] - 0s 170us/sample - loss: 1.8451\n",
      "Epoch 982/1000\n",
      "10/10 [==============================] - 0s 276us/sample - loss: 1.8448\n",
      "Epoch 983/1000\n",
      "10/10 [==============================] - 0s 984us/sample - loss: 1.8446\n",
      "Epoch 984/1000\n",
      "10/10 [==============================] - 0s 785us/sample - loss: 1.8443\n",
      "Epoch 985/1000\n",
      "10/10 [==============================] - 0s 330us/sample - loss: 1.8441\n",
      "Epoch 986/1000\n",
      "10/10 [==============================] - 0s 240us/sample - loss: 1.8439\n",
      "Epoch 987/1000\n",
      "10/10 [==============================] - 0s 220us/sample - loss: 1.8436\n",
      "Epoch 988/1000\n",
      "10/10 [==============================] - 0s 257us/sample - loss: 1.8434\n",
      "Epoch 989/1000\n",
      "10/10 [==============================] - 0s 471us/sample - loss: 1.8431\n",
      "Epoch 990/1000\n",
      "10/10 [==============================] - 0s 220us/sample - loss: 1.8429\n",
      "Epoch 991/1000\n",
      "10/10 [==============================] - 0s 312us/sample - loss: 1.8427\n",
      "Epoch 992/1000\n",
      "10/10 [==============================] - 0s 249us/sample - loss: 1.8424\n",
      "Epoch 993/1000\n",
      "10/10 [==============================] - 0s 409us/sample - loss: 1.8422\n",
      "Epoch 994/1000\n",
      "10/10 [==============================] - 0s 229us/sample - loss: 1.8420\n",
      "Epoch 995/1000\n",
      "10/10 [==============================] - 0s 843us/sample - loss: 1.8417\n",
      "Epoch 996/1000\n",
      "10/10 [==============================] - 0s 242us/sample - loss: 1.8415\n",
      "Epoch 997/1000\n",
      "10/10 [==============================] - 0s 210us/sample - loss: 1.8413\n",
      "Epoch 998/1000\n",
      "10/10 [==============================] - 0s 420us/sample - loss: 1.8410\n",
      "Epoch 999/1000\n",
      "10/10 [==============================] - 0s 230us/sample - loss: 1.8408\n",
      "Epoch 1000/1000\n",
      "10/10 [==============================] - 0s 455us/sample - loss: 1.8406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f586c2c2828>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_probability as tfp\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "neg_log_likelihood = lambda y, rv: -rv.log_prob(y)\n",
    "\n",
    "def build_model():\n",
    "    \"\"\"Regularization via kernel and bias regularizer\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(1, activation='linear', input_shape=[D]), \n",
    "        tfp.layers.DistributionLambda(lambda t: tfd.Normal(loc=t, scale=1)) \n",
    "    ])\n",
    "    \n",
    "    model.compile(loss=neg_log_likelihood)\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "model.fit(x, y, epochs=1000, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape Tensor(\"dense_input:0\", shape=(None, 1), dtype=float32) for input (None, 1), but it was re-called on a Tensor with incompatible shape (100, 1, 1).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 1, 1), dtype=float32, numpy=\n",
       "array([[[-5.202305  ]],\n",
       "\n",
       "       [[-5.103921  ]],\n",
       "\n",
       "       [[-5.005537  ]],\n",
       "\n",
       "       [[-4.907153  ]],\n",
       "\n",
       "       [[-4.8087697 ]],\n",
       "\n",
       "       [[-4.710386  ]],\n",
       "\n",
       "       [[-4.6120024 ]],\n",
       "\n",
       "       [[-4.5136185 ]],\n",
       "\n",
       "       [[-4.415235  ]],\n",
       "\n",
       "       [[-4.3168507 ]],\n",
       "\n",
       "       [[-4.218467  ]],\n",
       "\n",
       "       [[-4.1200833 ]],\n",
       "\n",
       "       [[-4.0216994 ]],\n",
       "\n",
       "       [[-3.923316  ]],\n",
       "\n",
       "       [[-3.8249323 ]],\n",
       "\n",
       "       [[-3.7265484 ]],\n",
       "\n",
       "       [[-3.6281648 ]],\n",
       "\n",
       "       [[-3.529781  ]],\n",
       "\n",
       "       [[-3.4313972 ]],\n",
       "\n",
       "       [[-3.3330135 ]],\n",
       "\n",
       "       [[-3.2346299 ]],\n",
       "\n",
       "       [[-3.1362462 ]],\n",
       "\n",
       "       [[-3.0378623 ]],\n",
       "\n",
       "       [[-2.9394786 ]],\n",
       "\n",
       "       [[-2.8410947 ]],\n",
       "\n",
       "       [[-2.742711  ]],\n",
       "\n",
       "       [[-2.6443272 ]],\n",
       "\n",
       "       [[-2.5459435 ]],\n",
       "\n",
       "       [[-2.4475598 ]],\n",
       "\n",
       "       [[-2.349176  ]],\n",
       "\n",
       "       [[-2.2507923 ]],\n",
       "\n",
       "       [[-2.1524086 ]],\n",
       "\n",
       "       [[-2.0540247 ]],\n",
       "\n",
       "       [[-1.9556412 ]],\n",
       "\n",
       "       [[-1.8572574 ]],\n",
       "\n",
       "       [[-1.7588737 ]],\n",
       "\n",
       "       [[-1.6604899 ]],\n",
       "\n",
       "       [[-1.5621063 ]],\n",
       "\n",
       "       [[-1.4637225 ]],\n",
       "\n",
       "       [[-1.3653388 ]],\n",
       "\n",
       "       [[-1.266955  ]],\n",
       "\n",
       "       [[-1.168571  ]],\n",
       "\n",
       "       [[-1.0701876 ]],\n",
       "\n",
       "       [[-0.97180355]],\n",
       "\n",
       "       [[-0.8734201 ]],\n",
       "\n",
       "       [[-0.7750361 ]],\n",
       "\n",
       "       [[-0.6766526 ]],\n",
       "\n",
       "       [[-0.57826865]],\n",
       "\n",
       "       [[-0.47988468]],\n",
       "\n",
       "       [[-0.3815012 ]],\n",
       "\n",
       "       [[-0.28311723]],\n",
       "\n",
       "       [[-0.18473373]],\n",
       "\n",
       "       [[-0.08634977]],\n",
       "\n",
       "       [[ 0.01203373]],\n",
       "\n",
       "       [[ 0.11041769]],\n",
       "\n",
       "       [[ 0.20880118]],\n",
       "\n",
       "       [[ 0.30718514]],\n",
       "\n",
       "       [[ 0.40556863]],\n",
       "\n",
       "       [[ 0.5039526 ]],\n",
       "\n",
       "       [[ 0.60233605]],\n",
       "\n",
       "       [[ 0.7007201 ]],\n",
       "\n",
       "       [[ 0.7991035 ]],\n",
       "\n",
       "       [[ 0.8974875 ]],\n",
       "\n",
       "       [[ 0.99587095]],\n",
       "\n",
       "       [[ 1.094255  ]],\n",
       "\n",
       "       [[ 1.1926389 ]],\n",
       "\n",
       "       [[ 1.2910224 ]],\n",
       "\n",
       "       [[ 1.3894063 ]],\n",
       "\n",
       "       [[ 1.4877899 ]],\n",
       "\n",
       "       [[ 1.5861738 ]],\n",
       "\n",
       "       [[ 1.6845574 ]],\n",
       "\n",
       "       [[ 1.7829413 ]],\n",
       "\n",
       "       [[ 1.8813248 ]],\n",
       "\n",
       "       [[ 1.9797087 ]],\n",
       "\n",
       "       [[ 2.0780923 ]],\n",
       "\n",
       "       [[ 2.1764762 ]],\n",
       "\n",
       "       [[ 2.2748597 ]],\n",
       "\n",
       "       [[ 2.3732436 ]],\n",
       "\n",
       "       [[ 2.4716272 ]],\n",
       "\n",
       "       [[ 2.5700111 ]],\n",
       "\n",
       "       [[ 2.6683946 ]],\n",
       "\n",
       "       [[ 2.7667785 ]],\n",
       "\n",
       "       [[ 2.8651626 ]],\n",
       "\n",
       "       [[ 2.9635465 ]],\n",
       "\n",
       "       [[ 3.0619295 ]],\n",
       "\n",
       "       [[ 3.1603136 ]],\n",
       "\n",
       "       [[ 3.2586975 ]],\n",
       "\n",
       "       [[ 3.3570814 ]],\n",
       "\n",
       "       [[ 3.4554644 ]],\n",
       "\n",
       "       [[ 3.5538485 ]],\n",
       "\n",
       "       [[ 3.6522324 ]],\n",
       "\n",
       "       [[ 3.7506166 ]],\n",
       "\n",
       "       [[ 3.8489995 ]],\n",
       "\n",
       "       [[ 3.9473834 ]],\n",
       "\n",
       "       [[ 4.0457673 ]],\n",
       "\n",
       "       [[ 4.144151  ]],\n",
       "\n",
       "       [[ 4.242535  ]],\n",
       "\n",
       "       [[ 4.340918  ]],\n",
       "\n",
       "       [[ 4.4393024 ]],\n",
       "\n",
       "       [[ 4.5376863 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xs).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_probability import edward2 as ed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the estimator API\n",
    "* within the estimator API the number of training steps is controlled via the the `dataset`\n",
    "* more precisely via the `repeat` keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparision of results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
