{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "- For each categorical variable we want one embedding layer\n",
    "- https://machinelearningmastery.com/how-to-prepare-categorical-data-for-deep-learning-in-python/\n",
    "- For each non-categorical variable we want to have an dense layer of same dimension\n",
    "\n",
    "- We will work with data of the form shape `(batch_size, time_steps, features)`\n",
    "- For *each feature* we want an embedding of the form `(batch_size, time_steps, embedding_dim)`\n",
    "- Finally all embedded features are concatenated (along the feature axis)\n",
    "\n",
    "### Learning\n",
    "- **Categorical variables**\n",
    "- Use `TimeDistributed`  layer on top of `Dense(embedding_dim)` layer in order to have the same embedding for each time step\n",
    "- We need to keep the dimensions upons slicing for features, `input = Tensor(..., feature_idx, None)`\n",
    "- Striclty speaking time distributed is not necessary for dense layers (from construction of the latter), however it seems to be more clean\n",
    "\n",
    "\n",
    "- **Categorical variabels** \n",
    "- First call sklearns `OrdinalEncoder` \n",
    "- Construct embedding layer, `Embedding(input_dim=input_dim, output_dim=embedding_dim, input_length=time_steps)`\n",
    "- Just slice date (no keep dims is required!) along feature axis `input = Tensor(..., feature_idx)`\n",
    "\n",
    "\n",
    "- **Making it static**\n",
    "- Assume we have data where a feature is static, that is time independent. Hence, for a given feature and sample (batch index) the tensor entries are constant. \n",
    "\n",
    "- In order to get a static entity, one could slice the time dependent embeddings (take an arbritary time index of the embedding)\n",
    "- Or, learn the embedding on a time slice (any time index will do  as the data are static).\n",
    "- These two approaches are equivalent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow keeping dims upon slicing single index\n",
    "- either slice an interval\n",
    "- or slice one index and include axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 3), dtype=int64, numpy=\n",
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6],\n",
       "        [ 7,  8,  9]],\n",
       "\n",
       "       [[10, 20, 30],\n",
       "        [40, 50, 60],\n",
       "        [70, 80, 90]]])>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "t = tf.convert_to_tensor(np.array([[[1,2,3],[4,5,6], [7,8,9]],\n",
    "                              [[10,20,30],[40,50,60], [70,80,90]]]))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 1), dtype=bool, numpy=\n",
       "array([[[ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True]]])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[...,None, 1] ==  t[...,1, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 1), dtype=bool, numpy=\n",
       "array([[[ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True]]])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[...,None, 1] == t[..., 1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int64, numpy=\n",
       "array([[10, 20, 30],\n",
       "       [40, 50, 60],\n",
       "       [70, 80, 90]])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data shape, (32, 100, 20)\n",
      "Contineous data with time distribution expected(batch_size, time, hidden_dim)) (32, 100, 60)\n",
      "    Dimensions of underlying dense layer [TensorShape([1, 60]), TensorShape([60])]\n",
      "Contineous data with time distribution expected(batch_size, time, hidden_dim)) (32, 100, 60)\n",
      "    Dimensions of underlying dense layer [TensorShape([1, 60]), TensorShape([60])]\n",
      "Categorical embedding shape: expected (batch, time, out_dim) (32, 100, 2)\n",
      "Static slice of categorical embedding: expected (batch,  out_dim) (32, 2)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "time_steps = 100\n",
    "n_features = 20\n",
    "hidden_dim = 60\n",
    "feature_index=1\n",
    "#xs = tf.random.normal(shape=(batch_size, time_steps, n_features))\n",
    "xs = tf.convert_to_tensor(np.random.randint(100, size=(batch_size, time_steps, n_features)))\n",
    "print(f\"input data shape, {xs.shape}\")\n",
    "\n",
    "\n",
    "# time dependent contineous variables\n",
    "input = xs[..., feature_index, None]\n",
    "dense_and_td = tf.keras.layers.Dense(hidden_dim, name=\"dense_and_td\")\n",
    "contineous_time_dependent = tf.keras.layers.TimeDistributed(dense_and_td)(input)\n",
    "print(f\"Contineous data with time distribution expected(batch_size, time, hidden_dim)) {contineous_time_dependent.shape}\")\n",
    "print(f\"    Dimensions of underlying dense layer {[info.shape for info in dense_and_td.trainable_weights]}\")\n",
    "\n",
    "\n",
    "\n",
    "#Experiment: time dependent contineous variables without time distributed layer\n",
    "input = xs[..., feature_index, None]\n",
    "dense = tf.keras.layers.Dense(hidden_dim, name=\"dense_no_td\")\n",
    "print(f\"Contineous data with time distribution expected(batch_size, time, hidden_dim)) {dense(input).shape}\")\n",
    "print(f\"    Dimensions of underlying dense layer {[info.shape for info in dense.trainable_weights]}\")\n",
    "\n",
    "\n",
    "\n",
    "# embedding (input_dim = 10, output_dim=2, input_length=time_steps)\n",
    "input=xs[:, :, 2]\n",
    "unique, _ = tf.unique(tf.reshape(input, [-1]))\n",
    "categorical_embedding = tf.keras.layers.Embedding(input_dim=len(unique), output_dim=2, input_length=time_steps)(xs[:, :, 2])\n",
    "print(f\"Categorical embedding shape: expected (batch, time, out_dim) {categorical_embedding.shape}\") #(batch, time, out_dim)\n",
    "\n",
    "# make static variable (take t=0) from categroical embedding\n",
    "print(\"Static slice of categorical embedding: expected (batch,  out_dim)\", categorical_embedding[:,0,:].shape)\n",
    "\n",
    "\n",
    "# Learning:\n",
    "# keep dims for dense layer embedding for cont variables\n",
    "# do not keep dims for categorical embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exkursion:  Time distributed dense layers for contineous embeddings\n",
    "- let's look at a static dataset, where each time entry is equal\n",
    "- is there a difference between a time distributed dense layer and a plain dense layer? \n",
    "- Are the results equal for each time?\n",
    "\n",
    "### Conclusions:\n",
    "- For dense layers time distribution does not make a difference\n",
    "    - The numbers of parameters is the same in the layer\n",
    "    - The result is the same for each time step\n",
    "    - The overall result ist the same\n",
    "- This seems to be side effect from the dense layer implementation\n",
    "- It seems to be more appropriate to use time distributed layers at is matches the problem requrement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up toy data\n",
    "x = tf.convert_to_tensor(np.random.randint(100, size=(batch_size, 1, n_features)))\n",
    "xs = tf.concat([x]*time_steps, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = xs[..., feature_index, None]\n",
    "kernel_initializer = tf.keras.initializers.Constant(2.)\n",
    "bias_initializer = tf.keras.initializers.Constant(3.)\n",
    "\n",
    "# time distributed dense\n",
    "td_dense = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(hidden_dim, name=\"time_distributed_dense\", \n",
    "                                                                 kernel_initializer=kernel_initializer, \n",
    "                                                                 bias_initializer=bias_initializer))\n",
    "# simple dense layer\n",
    "dense = tf.keras.layers.Dense(hidden_dim, name=\"plain_dense\", kernel_initializer=kernel_initializer, \n",
    "                                                                 bias_initializer=bias_initializer)\n",
    "\n",
    "td_dense_result = td_dense(input)\n",
    "dense_result = dense(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple dense [TensorShape([1, 60]), TensorShape([60])]\n",
      "time distributed dense [TensorShape([1, 60]), TensorShape([60])]\n"
     ]
    }
   ],
   "source": [
    "print(f\"simple dense {[info.shape for info in dense.trainable_weights]}\")\n",
    "print(f\"time distributed dense {[info.shape for info in td_dense.trainable_weights]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both approaches  agree on all timestep: True\n"
     ]
    }
   ],
   "source": [
    "agrees = []\n",
    "for t in range(time_steps):\n",
    "    agree = tf.reduce_all((td_dense_result[:, t, :]) == (dense_result[:, t, :])).numpy()\n",
    "    agrees.append(agree)\n",
    "print(f\"both approaches  agree on all timestep: {all(agrees)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense gives same result for each timestep: True\n"
     ]
    }
   ],
   "source": [
    "agrees = []\n",
    "for t in range(time_steps):\n",
    "    for tau in range(time_steps):\n",
    "        agree = tf.reduce_all((dense_result[:, t, :]) == (dense_result[:, tau, :])).numpy()\n",
    "        agrees.append(agree)\n",
    "print(f\"Dense gives same result for each timestep: {all(agrees)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time distributed dense gives same result for each timestep: True\n"
     ]
    }
   ],
   "source": [
    "agrees = []\n",
    "for t in range(time_steps):\n",
    "    for tau in range(time_steps):\n",
    "        agree = tf.reduce_all((td_dense_result[:, t, :]) == (td_dense_result[:, tau, :])).numpy()\n",
    "        agrees.append(agree)\n",
    "print(f\"Time distributed dense gives same result for each timestep: {all(agrees)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exkursion: check time dependent, categorical variables \n",
    "- we need to ordinal encode categorical variables!\n",
    "- Integers are not enough as we additionally require that there are no \"gaps\" between the possible values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "oe = OrdinalEncoder()\n",
    "oe.fit(xs[..., 1])\n",
    "encoded = tf.convert_to_tensor(oe.transform(xs[..., 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Dimension 29\n"
     ]
    }
   ],
   "source": [
    "uniques, _ = tf.unique(tf.reshape(encoded, [-1]))\n",
    "input_dim = len(uniques)\n",
    "output_dim = 5\n",
    "input_length = time_steps\n",
    "print(f\"Input Dimension {input_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_initializer = tf.keras.initializers.Constant(2.)\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=input_dim, \n",
    "                                     output_dim=output_dim, \n",
    "                                     input_length=input_length, \n",
    "                                     embeddings_initializer=embeddings_initializer)\n",
    "embedded = embedding_layer(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings over all time steps agree True\n"
     ]
    }
   ],
   "source": [
    "agrees = []\n",
    "for t in range(time_steps):\n",
    "    for tau in range(time_steps):\n",
    "        agree = tf.reduce_all(embedded[:, t, :] == embedded[:, tau, :]).numpy()\n",
    "        agrees.append(agree)\n",
    "print(f\"Embeddings over all time steps agree {all(agrees)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_embedding_layer = tf.keras.layers.Embedding(input_dim=input_dim, \n",
    "                                                   output_dim=output_dim, \n",
    "                                                   embeddings_initializer=embeddings_initializer)\n",
    "static_embedded = static_embedding_layer(encoded[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static embedding without input_dim agrees with time dependent embedding layer? True\n"
     ]
    }
   ],
   "source": [
    "agrees = tf.reduce_all(static_embedded == embedded[:, 0, :]).numpy()\n",
    "print(f\"Static embedding without input_dim agrees with time dependent embedding layer? {agrees}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
